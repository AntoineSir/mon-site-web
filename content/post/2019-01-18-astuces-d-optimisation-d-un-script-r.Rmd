---
title: Astuces d'optimisation d'un script R
author: Antoine Sireyjol
date: '2019-01-18'
slug: astuces-d-optimisation-d-un-script-r
categories:
  - R
tags:
  - benchmark
  - booléens
  - dplyr
  - microbenchmark
  - optimisation
  - R
  - sapply
header:
  caption: ''
  image: ''
---

```{r include=FALSE}
library(dplyr)
library(microbenchmark)
library(nycflights13)
flightstib <- as_tibble(flights)
df <- data.frame(id1 = c(1:100), idgpe = sample(50), replace = TRUE)
```

On regroupe ici quelques astuces pour optimiser le temps d'exécution d'un code R. On en propose pour l'instant quatre, mais le post pourra être actualisé par la suite. L'idée est de regrouper des situations auxquelles chacun pourrait être confronté. Les points explorés dans cette note sont les suivants :  

* Pour base R : la question de [l'application d'une fonction apply aux colonnes d'un data.frame][Définition d'une fonction apply sur les colonnes d'un dataframe].
* Pour dplyr : la [création d'une variable directement à l'intérieur de summarise()][Ralentissement de la vitesse d'exécution pour une création de variable directement à l'intérieur de summarise()].
* Pour dplyr : le temps d'exécution d'un [group_by par une variable caractère][group_by par une variable caractère].
* Pour dplyr : les [summarise() sur des booléens][Ralentissement de la vitesse d'exécution pour une statistique sur une variable booléenne]

# Définition d'une fonction apply sur les colonnes d'un dataframe
Imaginons que vous souhaitiez appliquer une fonction à un ensemble de variables d'un data.frame, définies dans une liste (par exemple pour faire une fonction qui appliquerait des statistiques sur un ensemble de variables choisies par l'utilisateur). On définit donc une telle liste de variables, dans la table `flights` du package `nycflights13`: 

```{r}
var <- c("dep_delay", "arr_delay", "air_time")
```

On sort ensuite les moyennes de ces trois variables avec `sapply`. En base R, cela peut s'écrire ainsi :  
  
**Option 1**
```{r message=FALSE, warning=FALSE, paged.print=FALSE}
sapply(var, function(x) sum(flights[[x]], na.rm = TRUE))
```
Mais aussi ainsi :  
  
**Option 2**
```{r message=FALSE, warning=FALSE, paged.print=FALSE}
sapply(flights[var], function(x) sum(x, na.rm = TRUE))
```
Cette dernière option pouvant se simplifier, puisqu'on n'a pas vraiment besoin de définir notre fonction à la volée dans ce cas :  
  
**Option 2 bis**
```{r message=FALSE, warning=FALSE, paged.print=FALSE}
sapply(flights[var], sum, na.rm = TRUE)
```
Ainsi, l'option 2 peut sembler à juste titre plus intuitive (ne serait-ce que parce qu'elle se simplifie avec l'option 2bis), pourtant l'option 1 est significativement plus rapide, comme le montre la fonction `microbenchmark` :
```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
microbenchmark::microbenchmark(times = 50, "Option 1" = {
  sapply(var, function(x) sum(flights[[x]], na.rm = TRUE))
}, "Option 2" = {
  sapply(flights[var], function(x) sum(x, na.rm = TRUE))
}, "Option 2 bis" = {
  sapply(flights[var], sum, na.rm = TRUE)
})
```
C'est bon à savoir, mais pour ce genre de traitement ça vaut le coup de s'intéresser aux méthodes `dplyr` et `data.table` qui offrent des solutions faciles et efficaces.

# group_by par une variable caractère

Quelque chose de très simple à faire pour optimiser ses codes en dplyr : ne pas faire de group_by sur des variables caractères mais sur des factors. On montre ici un exemple très simple sur la même base flights. Tout d'abord, faisons une moyenne des retards à l'arrivée groupée par le lieu d'origine : 
```{r eval=FALSE, include=TRUE}
flightstib %>% group_by(origin) %>% 
  summarize(mean_delay = mean(arr_delay, na.rm = TRUE))
```
On compare la rapidité de cette instruction, à celle-ci, qui fait la même chose sur une variable factor : 
```{r eval=FALSE, include=TRUE}
flightstib$originfac <- as.factor(flightstib$origin)
flightstib %>% group_by(originfac) %>% 
  summarize(mean_delay = mean(arr_delay, na.rm = TRUE))
```
Le résultat de la fonction `microbenchmark` appliquée à ces deux instructions donne : 
```{r echo=FALSE}
flightstib$originfac <- as.factor(flightstib$origin)
microbenchmark::microbenchmark(times = 100L, 
                               "group by character" = {
                                 flightstib %>% group_by(origin) %>% 
                                   summarize(mean_delay = mean(arr_delay, na.rm = TRUE))
                                 },
                               "group by factor" = {
                                 flightstib %>% group_by(originfac) %>% 
                                   summarize(mean_delay = mean(arr_delay, na.rm = TRUE))
                               })
```
La différence est de l'ordre de 20% et peut peser encore plus sur des tables plus volumineuses. Elle est attendue car le type factor est plus léger et convient parfaitement pour des statistiques groupées. Mais cela semble jouer particulièrement pour les instructions sur dplyr, comme le suggère [cette discussion sur le github de dplyr](https://github.com/tidyverse/dplyr/issues/2198). À noter qu'on ne compte pas dans la comparaison le temps de transposition d'une variable caractère en factor, puisque celui-ci peut être appliqué une seule fois pour de nombreuses instructions ou être appliqué au moment de l'import des bases. 

# Ralentissement de la vitesse d'exécution pour une création de variable directement à l'intérieur de summarise()
Si on reprend l'exemple donné dans [le précédent post](https://antoinesir.rbind.io/post/vitesses-d-agr%C3%A9gation-de-data-table-et-dplyr/), vous avez pu remarquer que :
```{r eval=FALSE}
# Rappel : df <- data.frame(id1 = c(1:100), idgpe = sample(50), replace = TRUE)
df %>% as_tibble() %>% mutate(var = rnorm(100)) %>% 
group_by(idgpe) %>% summarise(var_mean = mean(var)) -> output_tibble
```
pouvait se réécrire de manière plus directe (comme le fait d'ailleurs la partie sur data.table) ainsi : 
```{r eval=FALSE}
df %>% as_tibble() %>%  group_by(idgpe) %>% 
  summarise(var_mean = mean(rnorm(100))) -> output_tibble
```
C'est-à-dire en se passant du `mutate` pour remplacer `var` par sa valeur dans `summarise`.  
Hé bien, cette instruction n'est pas seulement présentée ainsi pour le plaisir de vous montrer la fonction `mutate`, mais aussi parce que la première option est bien plus rapide que la seconde, comme le montre la fonction `microbenchmark` : 

```{r}
microbenchmark::microbenchmark(times=100L, dplyr1 = {
  df %>% as_tibble() %>% mutate(var = rnorm(100)) %>% 
    group_by(idgpe) %>% summarise(var_mean = mean(var)) 
}, dplyr2 = {
  df %>% as_tibble() %>% group_by(idgpe) %>% 
    summarise(var_mean = mean(rnorm(100))) 
})
```

Ca peut sembler secondaire pour cet exemple, mais sur des grosses tables la différence va vraiment peser. Regardons par exemple les différences de performance de deux instructions `dplyr` agrégeant par heure une variable égale au pourcentage de retard à l'arrivée par rapport à la durée du vol en utilisant les données de `nycflights13`: 

```{r}
microbenchmark::microbenchmark(times=10L, dplyr_mutate = {
flightstib %>% mutate(propor_delay = arr_delay / air_time) %>% 
group_by(time_hour) %>% 
summarise(propor_delay = mean(propor_delay)) -> output_dplyr 
}, dplyr_sans_mutate = {
flightstib %>% group_by(time_hour) %>% 
summarise(propor_delay = mean(arr_delay / air_time)) -> output_dplyr 
})
```
Les performances changent du tout au tout. Il semblerait donc que cela soit une très mauvais pratique d'essayer de "sauter" l'étape du `mutate()`, sans doute parce que le `group_by` peine à traiter le regroupement d'une opération de variables pas encore regroupées. C'est une propriété de `summarise` qu'il est important d'avoir à l'esprit.

# Ralentissement de la vitesse d'exécution pour une statistique sur une variable booléenne
Imaginons maintenant que l'on crée une variable booléenne indiquant si le pourcentage de retard à l'arrivée est supérieur à 20%. 
 
```{r eval=FALSE, include=TRUE}
flightstib %>% mutate(bool_delay = (arr_delay / air_time > 0.20)) 
```
On peut vouloir savoir combien de vols connaisent un retard supérieur à 20% à chaque heure, en agrégeant cette première variable et en appliquant un sum() sur celle-ci. 
```{r}
flightstib %>% mutate(bool_delay = (arr_delay / air_time > 0.20)) %>% 
  group_by(time_hour) %>% summarise(delay_over_20p = sum(bool_delay)) -> stats
```
Cette instruction tourne sans problèmes, mais lentement du fait de la difficulté de `dplyr` à traiter une somme sur un booléen. Il vaut mieux alors définir dans `mutate` la variable `bool_delay` comme une variable numérique avec `as.numeric(arr_delay / air_time > 0.20)` pour optimiser la rapidité du code. Le tableau suivant donne le résultat du microbenchmark de ces deux options :
```{r echo=FALSE}
microbenchmark(times = 10L, 
               "bool" = {
                 flightstib %>% mutate(bool_delay = (arr_delay / air_time > 0.20)) %>% 
  group_by(time_hour) %>% summarise(delay_over_20p = sum(bool_delay))
                 },
  "as.numeric(bool)" = {
    flightstib %>% mutate(bool_delay = as.numeric(arr_delay / air_time > 0.20)) %>% 
  group_by(time_hour) %>% summarise(delay_over_20p = sum(bool_delay))
  })
```
Les gains en temps d'exécution sont particulièrement importants. On ne constate pas une telle différence avec `data.table` par exemple.
