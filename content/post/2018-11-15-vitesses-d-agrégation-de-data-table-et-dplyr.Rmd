---
title: Vitesses d'aggrégation de base R, data.table et dplyr
author: Antoine Sireyjol
date: '2018-12-11'
slug: vitesses-d-agrégation-de-data-table-et-dplyr
categories:
  - R
tags:
  - benchmark
  - data.table
  - dplyr
  - tidyverse
  - microbenchmark
header:
  caption: ''
  image: ''
output:
  blogdown::html_page:
    number_sections: no
    toc: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE)
```


```{r message=FALSE, warning=FALSE, include=FALSE}
library(tidyverse)
library(data.table)
library(microbenchmark)
test_group_by <- function(nbrow, nbgpe){
  test <- as_tibble(data.frame(x = rnorm(nbrow), y = sample(floor(nbgpe), replace = TRUE)))
  testDT <- as.data.table(test)
  return(autoplot(
    microbenchmark::microbenchmark(times = 10, unit="ms", 
                                   dplyr = test %>% group_by(y) %>% summarise(x = mean(x)),
                                   data.table = testDT[, .(x = mean(x)), by = .(y = y)],
                                   "Base R" = {
                                     tap <- tapply(test$x, test$y, mean)
                                     data.frame(x = tap, y = names(tap))}
                                   ),
    log = FALSE)
    + ggtitle(paste0(nbrow, " lignes pour ", nbgpe, " groupes ")) + expand_limits(y = 0))
}
```

Comme on a pu le voir par exemple dans le [précédent post](https://antoinesir.rbind.io/post/comparaisons-base-r-dplyr-data-table/), l'aggrégation est souvent utilisée en analyse de données. Il est donc intéressant de comparer les performances des différentes options que propose R de ce point de vue. Des benchmarks comparant `data.table`, `dplyr` et la librairie `pandas` de python sur différentes tailles de tables ont déjà été faits, vous pouvez les trouver sur [cette page github](https://github.com/Rdatatable/data.table/wiki/Benchmarks-%3A-Grouping). On propose ici quelques tests comparatifs complémentaires sur un cas d'un calcul simple à partir d'un groupement d'une base fictive de `nbrow` lignes appartenant à `nbgpe` groupes. La fonction s'applique à deux variables numériques `x` et `y`, la première étant une variable aléatoire et la seconde un entier dont on fait varier le nombre de modalités. On teste l'instruction suivante :  

__Pour dplyr__
```{r eval=FALSE, include=TRUE}
datatib %>% group_by(y) %>% summarise(x = mean(x))
```

__Pour data.table__
```{r eval=FALSE, include=TRUE}
dataDT[, .(x = mean(x)), by = .(y = y)]
```

__Pour base R__
```{r eval=FALSE, include=TRUE}
tap <- tapply(test$x, test$y, mean)
data.frame(x = tap, y = names(tap))
```
Notons que dans ce dernier cas, on ajoute une étape pour transformer l'output en dataframe. On aurait aussi pu utiliser la fonction `aggregate` qui permet cela.

Il n'y a plus qu'à tester! On propose des tests sur 10 000, 100 000 et 1 million de lignes avec à chaque fois peu (1/1000e du nombre de lignes) ou beaucoup (la moitié du nombre de lignes) de groupes. On fait un tableau récapitulatif des différents graphiques issus de la fonction `autoplot` de  `ggplot2` qui sort joliment les résultats de `microbenchmark` (on regroupe ces graphiques à l'aide du package `gridExtra`). Les graphiques représentent la distribution du temps d'exécution des 10 occurences testées par méthode.

```{r echo=FALSE, message=FALSE, warning=FALSE}
x <- 1000
y <- 1
for (i in seq(1, 3)){
  x <- x * 10
  y <- y * 10
  assign(paste0("plot", i, sep = ""), test_group_by(x, y))
}
x <- 1000
y <- 500
for (i in seq(4, 6)){
  x <- x * 10
  y <- y * 10
  assign(paste0("plot", i, sep = ""), test_group_by(x, y))
}

library(gridExtra)
grid.arrange(plot1, plot4, plot2, plot5, plot3, plot6, ncol = 2, heights = c(8, 8, 8))

```

Le premier constat est que la méthode `data.table` est toujours plus rapide que les alternatives testées. Le second est que R base concurrence `dplyr` dans tous les cas où le nombre de groupes sur lesquels il faut agréger est petit. Au contraire, la fonction `tapply` est largement en dessous des performances des deux autres options quand le nombre de groupes est élevé.  
Le changement d'échelle du graphique à chaque hypothèse testée est trompeur mais ne doit pas cacher que dans le cas d'une table à 1 million de lignes et 50 000 groupes, si l'option `dplyr` fait largement mieux que R base, elle est aussi plus surpassée que jamais par data.table. Regardons le graphique de résultats de cette hypothèse pour mieux s'en rendre compte :  

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
plot6
```

Les temps d'exécution de `data.table` se situent autour de 100 millisecondes alors que ceux de `dplyr` sont autour de 800 millisecondes.  

Ces tests confirment ceux cités en introduction de ce post. Ils montrent l'intérêt d'utiliser `data.table` dans le cas d'instructions agrégées si l'on souhaite optimiser le temps d'exécution de son script et/ou si l'on connaît des difficultés à gérer des tables volumineuses. Ils montrent aussi que `dplyr` reste une option crédible et très compétitive notamment par rapport aux fonctions de base R.
