<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Antoine Sireyjol on Antoine Sireyjol</title>
    <link>/</link>
    <description>Recent content in Antoine Sireyjol on Antoine Sireyjol</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>fr</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 +0200</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Vitesses d&#39;aggrégation de base R, data.table et dplyr</title>
      <link>/post/vitesses-d-agr%C3%A9gation-de-data-table-et-dplyr/</link>
      <pubDate>Tue, 11 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/vitesses-d-agr%C3%A9gation-de-data-table-et-dplyr/</guid>
      <description>&lt;p&gt;Comme on a pu le voir par exemple dans le &lt;a href=&#34;https://antoinesir.rbind.io/post/comparaisons-base-r-dplyr-data-table/&#34;&gt;précédent post&lt;/a&gt;, l’aggrégation est souvent utilisée en analyse de données. Il est donc intéressant de comparer les performances des différentes options que propose R de ce point de vue. Des benchmarks comparant &lt;code&gt;data.table&lt;/code&gt;, &lt;code&gt;dplyr&lt;/code&gt; et la librairie &lt;code&gt;pandas&lt;/code&gt; de python sur différentes tailles de tables ont déjà été faits, vous pouvez les trouver sur &lt;a href=&#34;https://github.com/Rdatatable/data.table/wiki/Benchmarks-%3A-Grouping&#34;&gt;cette page github&lt;/a&gt;. On propose ici quelques tests comparatifs complémentaires sur un cas d’un calcul simple à partir d’un groupement d’une base fictive de &lt;code&gt;nbrow&lt;/code&gt; lignes appartenant à &lt;code&gt;nbgpe&lt;/code&gt; groupes. La fonction s’applique à deux variables numériques &lt;code&gt;x&lt;/code&gt; et &lt;code&gt;y&lt;/code&gt;, la première étant une variable aléatoire et la seconde un entier dont on fait varier le nombre de modalités. On teste l’instruction suivante :&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pour dplyr&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;datatib %&amp;gt;% group_by(y) %&amp;gt;% summarise(x = mean(x))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Pour data.table&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dataDT[, .(x = mean(x)), by = .(y = y)]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Pour base R&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tap &amp;lt;- tapply(test$x, test$y, mean)
data.frame(x = tap, y = names(tap))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notons que dans ce dernier cas, on ajoute une étape pour transformer l’output en dataframe. On aurait aussi pu utiliser la fonction &lt;code&gt;aggregate&lt;/code&gt; qui permet cela.&lt;/p&gt;
&lt;p&gt;Il n’y a plus qu’à tester! On propose des tests sur 10 000, 100 000 et 1 million de lignes avec à chaque fois peu (1/1000e du nombre de lignes) ou beaucoup (la moitié du nombre de lignes) de groupes. On fait un tableau récapitulatif des différents graphiques issus de la fonction &lt;code&gt;autoplot&lt;/code&gt; de &lt;code&gt;ggplot2&lt;/code&gt; qui sort joliment les résultats de &lt;code&gt;microbenchmark&lt;/code&gt; (on regroupe ces graphiques à l’aide du package &lt;code&gt;gridExtra&lt;/code&gt;). Les graphiques représentent la distribution du temps d’exécution des 10 occurences testées par méthode.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-11-15-vitesses-d-agrégation-de-data-table-et-dplyr_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Le premier constat est que la méthode &lt;code&gt;data.table&lt;/code&gt; est toujours plus rapide que les alternatives testées. Le second est que R base concurrence &lt;code&gt;dplyr&lt;/code&gt; dans tous les cas où le nombre de groupes sur lesquels il faut agréger est petit. Au contraire, la fonction &lt;code&gt;tapply&lt;/code&gt; est largement en dessous des performances des deux autres options quand le nombre de groupes est élevé.&lt;br /&gt;
Le changement d’échelle du graphique à chaque hypothèse testée est trompeur mais ne doit pas cacher que dans le cas d’une table à 1 million de lignes et 50 000 groupes, si l’option &lt;code&gt;dplyr&lt;/code&gt; fait largement mieux que R base, elle est aussi plus surpassée que jamais par data.table. Regardons le graphique de résultats de cette hypothèse pour mieux s’en rendre compte :&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-11-15-vitesses-d-agrégation-de-data-table-et-dplyr_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Les temps d’exécution de &lt;code&gt;data.table&lt;/code&gt; se situent autour de 100 millisecondes alors que ceux de &lt;code&gt;dplyr&lt;/code&gt; sont autour de 800 millisecondes.&lt;/p&gt;
&lt;p&gt;Ces tests confirment ceux cités en introduction de ce post. Ils montrent l’intérêt d’utiliser &lt;code&gt;data.table&lt;/code&gt; dans le cas d’instructions agrégées si l’on souhaite optimiser le temps d’exécution de son script et/ou si l’on connaît des difficultés à gérer des tables volumineuses. Ils montrent aussi que &lt;code&gt;dplyr&lt;/code&gt; reste une option crédible et très compétitive notamment par rapport aux fonctions de base R.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Comparaisons base R - dplyr - data.table</title>
      <link>/post/comparaisons-base-r-dplyr-data-table/</link>
      <pubDate>Mon, 03 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/comparaisons-base-r-dplyr-data-table/</guid>
      <description>&lt;p&gt;La richesse de R, alimentée par une communauté de développeurs très active, rend le choix d’une méthode adaptée à une problématique donnée difficile, et c’est tant mieux. Vous trouverez ici une modeste participation au débat qui oppose les deux packages d’analyse des données les plus en vue dans la communauté R : &lt;code&gt;data.table&lt;/code&gt; et &lt;code&gt;dplyr&lt;/code&gt;. L’article se présente en deux parties :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#rappels-sur-dplyr-et-data.table&#34;&gt;Un rappel sur les syntaxes de dplyr et data.table&lt;/a&gt;, que vous pouvez passer si vous connaissez déjà les packages.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#comparaisons-sur-une-etude-de-cas-simple&#34;&gt;Une comparaison de l’efficacité des deux packages&lt;/a&gt; sur une étude de cas à partir des données du package &lt;code&gt;nycflights13&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;rappels-sur-dplyr-et-data.table&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Rappels sur dplyr et data.table&lt;/h1&gt;
&lt;p&gt;Si vous connaissez déjà la syntaxe de ces packages, vous pouvez directement aller à la partie &lt;a href=&#34;#comparaisons-sur-une-etude-de-cas-simple&#34;&gt;Comparaisons sur une étude de cas simple&lt;/a&gt;. On rappelle ici les principales caractéristiques de ces packages mais pour se former à leur utilisation on peut se référer au &lt;a href=&#34;https://teaching.slmc.fr/perf/presentation_handout.pdf&#34;&gt;cours de perfectionnement de Martin Chevalier&lt;/a&gt;. Pour une exploration de ce qu’englobe le &lt;code&gt;tidyverse&lt;/code&gt; et notamment une présentation des commandes de &lt;code&gt;dplyr&lt;/code&gt;, vous pouvez jeter un oeil à &lt;a href=&#34;https://juba.github.io/tidyverse/index.html&#34;&gt;l’introduction à R et au tidyverse&lt;/a&gt; de J. Barnier. Enfin pour data.table, on trouve des informations utiles sur le cours &lt;a href=&#34;http://larmarange.github.io/analyse-R/manipulations-avancees-avec-data-table.html&#34;&gt;Manipulations avancée avec data.table&lt;/a&gt; de J. Larmarange.&lt;/p&gt;
&lt;div id=&#34;dplyr-et-le-tidyverse&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;dplyr et le tidyverse&lt;/h2&gt;
&lt;p&gt;Le &lt;code&gt;tidyverse&lt;/code&gt; (contraction de “tidy” et “universe”) est un concept initié par Hadley Wickham, chef statisticien de RStudio. Il regroupe un ensemble de packages utiles au traitement statistique et au nettoyage de bases de données. On va s’intéresser ici presque seulement au package &lt;code&gt;dplyr&lt;/code&gt; (dont les instructions seront appliquées aux &lt;code&gt;tibbles&lt;/code&gt;, un format de data.frame issu du &lt;code&gt;tidyverse&lt;/code&gt;), mais vous pouvez parcourir les packages proposés dans le tidyverse sur &lt;a href=&#34;https://www.tidyverse.org/&#34;&gt;le site officiel&lt;/a&gt;.&lt;br /&gt;
&lt;code&gt;dplyr&lt;/code&gt; propose un ensemble d’opérations de traitement de données sous une syntaxe différente de celle utilisée dans les fonctions de base de R. Ce langage présente le double avantage d’être à la fois lisible pour quelqu’un habitué aux langages tels que SAS ou SQL et de proposer des fonctions optimisées qui présentent de bonnes performances en termes de temps d’exécution. La grammaire &lt;code&gt;dplyr&lt;/code&gt; s’appuie en effet sur des fonctions au nom explicite :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;mutate(data, newvar1=fonction(var1,var2...))&lt;/code&gt; et &lt;code&gt;transmute(data, newvar1=fonction(var1,var2...))&lt;/code&gt; créent de nouvelles variables&lt;/li&gt;
&lt;li&gt;&lt;code&gt;filter(data, condition)&lt;/code&gt; sélectionne au sein d’une table certaines observations, à la manière de &lt;code&gt;where&lt;/code&gt; dans SAS.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;arrange(data, var1, descending var2,...)&lt;/code&gt; trie une base selon une ou plusieurs variables (l’équivalent d’une &lt;code&gt;proc sort&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;select(data, var1 : varX)&lt;/code&gt; sélectionne certaines variables dans une base, à la manière de &lt;code&gt;keep&lt;/code&gt; dans SAS.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;summarise(data, newvar1=mean(var1), newvar2=sum(var2))&lt;/code&gt; réalise toute sorte d’opérations statistiques sur une table.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;group_by(data, var)&lt;/code&gt; regroupe une table par une variable&lt;/li&gt;
&lt;li&gt;et bien d’autres…&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Un aspect pratique de ce langage est que toutes ces opérations peuvent être chaînées à l’aide de l’opérateur &lt;code&gt;%&amp;gt;%&lt;/code&gt; (“pipe” en anglais) dont la syntaxe est la suivante : &lt;code&gt;data %&amp;gt;% fonction(...)&lt;/code&gt; est équivalent à &lt;code&gt;fonction(data, ...)&lt;/code&gt;. Cette syntaxe permet de chaîner un grand nombre d’opérations sur une base commune, en limitant le nombre de fois où l’on écrit des tables intermédiaires tout en conservant une grande lisibilité du code. Ce petit exemple vous en convaincra peut-être :&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse) # On aurait aussi pu charger seulement le package dplyr
# on crée un data frame avec 100 lignes, chaque individu appartenant à un des 50 groupes
df &amp;lt;- data.frame(id1 = c(1:100), idgpe = sample(50), replace = TRUE)

# on y applique les instructions de dplyr
df %&amp;gt;% as_tibble() %&amp;gt;% mutate(var = rnorm(100)) %&amp;gt;% 
  group_by(idgpe) %&amp;gt;% summarise(var_mean = mean(var)) -&amp;gt; output_tibble&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Un regard peu habitué contesterait peut-être l’aspect très lisible de l’instruction, mais ça l’est réellement. Le déroulé est le suivant :&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;on transforme notre data.frame en tibble (pour rappel : format optimisé de data.frame pour dplyr) avec &lt;code&gt;as_tibble&lt;/code&gt;&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;on crée une variable &lt;code&gt;var&lt;/code&gt; avec &lt;code&gt;mutate&lt;/code&gt;&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;on agrège par &lt;code&gt;idgpe&lt;/code&gt; avec &lt;code&gt;group_by&lt;/code&gt;&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;on calcule la moyenne de &lt;code&gt;var&lt;/code&gt; avec &lt;code&gt;summarise&lt;/code&gt;, que l’on stocke dans &lt;code&gt;var_mean&lt;/code&gt;. Comme cette instruction suit un group_by, elle est réalisée à l’intérieur de chaque groupe (défini par &lt;code&gt;idgpe&lt;/code&gt;), sinon elle aurait été réalisé sur l’ensemble de la table.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Tout cela est stocké dans une table output_tibble, qui est ainsi un tibble agrégé par &lt;code&gt;idgpe&lt;/code&gt; et qui a donc 50 lignes. L’intérêt de ce chaînage est qu’il permet une économie de code et d’écriture d’éventuelles tables intermédiaires.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data.table&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data.table&lt;/h2&gt;
&lt;p&gt;Le package &lt;code&gt;data.table&lt;/code&gt; ne prétend pas, contrairement au &lt;code&gt;tidyverse&lt;/code&gt;, proposer une syntaxe concurrente à base R mais enrichir celle-ci. Il est axé autour d’un nouveau format d’objet, le data.table, qui est un type de data.frame qui permet une utilisation optimisée de l’opérateur &lt;code&gt;[&lt;/code&gt;.&lt;br /&gt;
Tout data.frame peut être converti en data.table grâce à la fonction &lt;code&gt;as.data.table&lt;/code&gt;, ou, de manière plus optimale pour l’utilisation de la mémoire, grâce à la fonction &lt;code&gt;setDT&lt;/code&gt; qui permet de directement transformer la nature de l’objet sans avoir à en écrire un autre. Il est important d’avoir en tête qu’un data.frame converti en data.table conserve les caractéristiques d’un data.frame. Cependant, l’opérateur &lt;code&gt;[&lt;/code&gt; appliqué au data.table change de signification et devient :&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;DT[i,j,by]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Avec &lt;code&gt;i&lt;/code&gt; qui permet de sélectionner des observations (sans avoir besoin de répéter le nom de la base dans laquelle on se trouve), &lt;code&gt;j&lt;/code&gt; qui permet de créer ou sélectionner des variables et &lt;code&gt;by&lt;/code&gt; de regrouper les traitement selon les modalités d’une variable définie. Comme dans &lt;code&gt;dplyr&lt;/code&gt;, il est possible de chaîner les opérations réalisées comme le montre l’exemple suivant, qui reprend le même cas de figure que celui illustrant le package &lt;code&gt;dplyr&lt;/code&gt; :&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(data.table) 
# on convertit notre data frame précédemment créé en data.table
dt &amp;lt;- as.data.table(df)

# on y applique les même instructions
dt[, list(var_mean = mean(rnorm(100))), by = list(idgpe = idgpe)] -&amp;gt; output_dt&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Le fait de renseigner mes variables au sein de &lt;code&gt;list()&lt;/code&gt; me permet d’avoir une table en sortie au niveau de &lt;code&gt;idgpe&lt;/code&gt; (donc 50 observations), sans cela ma variable est bien moyennée par groupe mais la table en sortie est toujours au niveau &lt;code&gt;id1&lt;/code&gt; (100 observations).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;vitesses-dexecution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Vitesses d’exécution&lt;/h2&gt;
&lt;p&gt;Voilà donc pour les présentations! Allez, on montre le résultat d’un petit &lt;code&gt;microbenchmark&lt;/code&gt; des deux juste pour voir :&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Unit: microseconds
##        expr      min       lq      mean   median        uq      max neval
##       dplyr 1531.449 1567.289 1753.4469 1596.303 1856.0005 4545.422   100
##  data.table  819.201  856.178  919.2454  901.405  974.7915 1233.921   100&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Sur cet exemple, on voit un avantage clair à data.table! Mais on est sur une toute petite table en entrée. On va essayer de se rapprocher de cas plus concrets en s’intéressant à un exemple sur des bases plus importantes.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;comparaisons-sur-une-etude-de-cas-simple&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Comparaisons sur une étude de cas simple&lt;/h1&gt;
&lt;p&gt;Les avantages et inconvénients de ces deux packages sont à l’origine de nombreux débats. Vous pouvez vous en convaincre en suivant &lt;a href=&#34;https://stackoverflow.com/questions/21435339/data-table-vs-dplyr-can-one-do-something-well-the-other-cant-or-does-poorly&#34;&gt;cette discussion sur stackoverflow&lt;/a&gt;. On peut quand même dégager deux compromis :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Le choix de l’un ou l’autre des packages dépend beaucoup de ce que l’on va en faire (types d’analyses, taille des données, profils des utilisateurs du code…).&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Les deux packages sont plus intéressants que base R pour l’analyse de données, que ce soit en termes de facilité d’écriture ou de performances.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Pour ce deuxième point, on va essayer de s’en convaincre ensemble avec ce petit exemple.&lt;/p&gt;
&lt;div id=&#34;notre-etude-de-cas&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Notre étude de cas&lt;/h2&gt;
&lt;p&gt;Pour cet exemple, on utilise les données du package de Hadley Wickham que l’on trouve dans &lt;code&gt;nycflights13&lt;/code&gt;. En particulier, la base &lt;code&gt;flights&lt;/code&gt; donne toutes les heures de départ et d’arrivée selon les aéroports de départ et d’arrivée ainsi que les retards au départ et à l’arrivée. La base &lt;code&gt;weather&lt;/code&gt; donne elle des indications météo, heure par heure, dans chaque aéroport. Tout bon statisticien qui se respecte devrait commencer à se dire qu’il y a quelque chose à faire pour tenter d’expliquer les retards des avions (&lt;em&gt;spoiler alert&lt;/em&gt; : on ne va pas le faire).&lt;br /&gt;
Commençons par charger nos packages (n’oubliez pas de faire &lt;code&gt;install.packages(&amp;quot;nom_pck&amp;quot;)&lt;/code&gt; avant si vous ne l’avez jamais fait) et nos données :&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Les packages nécessaires
library(tidyverse) # Regroupe différents packages, voir https://www.tidyverse.org/ 
library(data.table)
library(microbenchmark) # Pour les calculs de vitesse d&amp;#39;exécution
library(nycflights13) # Pour les données

# data.table pour tests avec data.table
flightsdt &amp;lt;- as.data.table(flights)
weatherdt &amp;lt;- as.data.table(weather)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notez que l’on n’est pas obligés de faire du dplyr sur des tibbles plutôt que des data frame, mais on suit ici les recommandations d’Hadley Wickham.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;moyenne-des-retards-et-fusion-des-tables&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Moyenne des retards et fusion des tables&lt;/h2&gt;
&lt;p&gt;Un rapide examen des bases vous montre que la première étape avant toute analyse est comme souvent de regrouper les éléments de flights par heure et aéroport de départ pour pouvoir les fusionner avec la table weather, qui donnent les indications météo minute par minute. On écrit cette instruction de 3 manières différentes :&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;En base R&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flights_time_hour &amp;lt;- aggregate.data.frame(list(arr_delay = flights$arr_delay, 
                                    dep_delay = flights$dep_delay), 
                                      list(time_hour = flights$time_hour, origin = flights$origin), 
                                      mean)
output_base &amp;lt;- merge(weather, flights_time_hour, by = c(&amp;quot;time_hour&amp;quot;, &amp;quot;origin&amp;quot;), sort = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(J’ai utilisé &lt;code&gt;aggregate.data.frame&lt;/code&gt; et pas &lt;code&gt;tapply&lt;/code&gt; pour avoir directement un data.frame en sortie)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;En dplyr&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flights %&amp;gt;% group_by(time_hour, origin) %&amp;gt;% 
  summarise(arr_delay = mean(arr_delay),
            dep_delay = mean(dep_delay)) %&amp;gt;% 
  inner_join(weather, by = c(&amp;quot;time_hour&amp;quot;, &amp;quot;origin&amp;quot;)) -&amp;gt; output_dplyr &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;En data.table&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;output_DT &amp;lt;- merge(flightsdt[, list(arr_perc_delay = mean(arr_delay),
                       dep_perc_delay = mean(dep_delay)), by = c(&amp;quot;time_hour&amp;quot;, &amp;quot;origin&amp;quot;)],
      weatherdt, by = c(&amp;quot;time_hour&amp;quot;, &amp;quot;origin&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;J’ai utilisé la fonction &lt;code&gt;merge&lt;/code&gt; plutôt que &lt;code&gt;DT1[DT2, on = c(&amp;quot;time_hour&amp;quot;, &amp;quot;origin&amp;quot;), nomatch = 0]&lt;/code&gt; car j’ai constaté qu’elle était plus rapide, conformément à ce que montre bien cet &lt;a href=&#34;https://jozefhajnala.gitlab.io/r/r006-merge/&#34;&gt;article du Jozef’s Rblog&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;comparaisons-des-vitesses-dexecution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Comparaisons des vitesses d’exécution&lt;/h2&gt;
&lt;p&gt;Je vous laisse juger de la lisibilité de chacune de ces instructions, qui font toutes la même chose, car c’est finalement assez subjectif. On donne ici les résultats d’un &lt;code&gt;microbenchmark&lt;/code&gt; de ces instructions :&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Unit: milliseconds
##   expr        min         lq       mean     median         uq        max
##   Base 2313.60446 2492.01024 2631.20076 2704.05612 2753.71612 2868.66635
##  DplyR   55.56166   58.76165   62.45664   61.29150   65.58718   71.77726
##     DT   32.77311   33.92625   35.76353   35.02335   38.23842   39.83814
##  neval
##     10
##     10
##     10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Les résultats sont très nettement en faveur des packages &lt;code&gt;dplyr&lt;/code&gt; et &lt;code&gt;data.table&lt;/code&gt;, ce dernier ayant l’avantage. Sans doute existe-t-il des moyens de plus optimiser l’instruction en base R, mais là n’est pas vraiment la question. On voit qu’avec une syntaxe simple et lisible, &lt;code&gt;dplyr&lt;/code&gt; et &lt;code&gt;data.table&lt;/code&gt; font beaucoup mieux que l’instruction qui viendrait à l’esprit d’un statisticien qui n’utiliserait que les premières fonctions venues de base R.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Privacy Policy</title>
      <link>/privacy/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0200</pubDate>
      
      <guid>/privacy/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
