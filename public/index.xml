<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Antoine Sireyjol - statisticien freelance on Antoine Sireyjol - statisticien freelance</title>
    <link>/</link>
    <description>Recent content in Antoine Sireyjol - statisticien freelance on Antoine Sireyjol - statisticien freelance</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>fr</language>
    <copyright>&amp;copy; 2019</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 +0200</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Gestion des packages sur R : présentation de packrat</title>
      <link>/post/gestion-des-packages-sur-r-pr%C3%A9sentation-de-packrat/</link>
      <pubDate>Thu, 09 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/gestion-des-packages-sur-r-pr%C3%A9sentation-de-packrat/</guid>
      <description>&lt;p&gt;Packrat est un système de gestion de packages et de leurs versions permettant de tracer l’installation et l’utilisation de ceux-ci dans un projet R. Cet article vise à vous montrer comment l’utiliser et en quoi il peut vous être utile. Le plan de l’article est le suivant :&lt;br /&gt;
- &lt;a href=&#34;#packrat-ca-sert-a-quoi&#34;&gt;Packrat, ça sert à quoi?&lt;/a&gt;&lt;br /&gt;
- &lt;a href=&#34;#demarrer-son-projet-avec-packrat&#34;&gt;Démarrer son projet avec packrat&lt;/a&gt;&lt;br /&gt;
- &lt;a href=&#34;#utiliser-packrat-avec-un-outil-de-gestion-de-versions&#34;&gt;Utiliser packrat avec un outil de gestion de versions&lt;/a&gt;&lt;br /&gt;
- &lt;a href=&#34;#quelques-limites&#34;&gt;Quelques limites&lt;/a&gt;&lt;/p&gt;
&lt;div id=&#34;packrat-ca-sert-a-quoi&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Packrat, ça sert à quoi?&lt;/h1&gt;
&lt;p&gt;Packrat trace tous les packages installés pour un projet ainsi que leurs dépendances. Ce gestionnaire de packages est lui-même un package R qui peut s’installer avec l’instruction &lt;code&gt;install.packages(&amp;quot;packrat&amp;quot;)&lt;/code&gt;. La documentation et l’aide pour l’utilisation de packrat sont disponibles &lt;a href=&#34;https://rstudio.github.io/packrat/&#34;&gt;ici&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Dans une utilisation classique de R, les packages que vous installez se trouvent généralement tous dans le même dossier, au niveau du dossier d’installation de R. Avec packrat, les packages que vous installez pour votre projet vont se retrouver dans un dossier &lt;code&gt;packrat&lt;/code&gt; au niveau de votre projet. Ce seul élément permet déjà de vous assurer que vous allez pouvoir identifier facilement les packages que vous avez installés pour votre projet et pour lui seul. En plus de cela, packrat va recenser à chaque installation de package que vous réalisez la version du package au moment où vous l’avez installé ainsi que les dépendances de celui-ci. Il va mettre ces informations dans un fichier &lt;em&gt;lock&lt;/em&gt;. C’est ce fichier qui permet ensuite de pouvoir récupérer l’ensemble des versions des packages utilisées dans votre projet depuis n’importe quel poste.&lt;/p&gt;
&lt;p&gt;Ces caractéristiques permettent ainsi de mettre à l’abri votre projet de mises à jours de packages non désirées, puisque la mise à jour de packages sur d’autres projets n’aura pas d’impacts sur votre projet avec packrat. &lt;a href=&#34;https://rstudio.github.io/packrat/&#34;&gt;La documentation packrat&lt;/a&gt; définit cela comme un projet &lt;strong&gt;isolé&lt;/strong&gt;. La &lt;strong&gt;portabilité&lt;/strong&gt; et la &lt;strong&gt;reproductibilité&lt;/strong&gt; des projets réalisés avec packrat viennent du fait que le fichier &lt;em&gt;lock&lt;/em&gt; assure que les packages puissent être installés de n’importe quel poste (et n’importe quel système d’exploitation) et le soient dans la même version pour tout le monde. Dit autrement, si le projet tourne sur un poste, packrat assure qu’il tournera sur n’importe quel poste. Nous allons essayer de vous montrer concrètement comment cela fonctionne.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;demarrer-son-projet-avec-packrat&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Démarrer son projet avec packrat&lt;/h1&gt;
&lt;p&gt;La première chose à faire est d’installer le package &lt;code&gt;packrat&lt;/code&gt; sur une session R. Il s’appuie lui-même sur les packages &lt;code&gt;tools&lt;/code&gt; et &lt;code&gt;unit&lt;/code&gt;. Il se peut que les droits d’administrateur sur le poste soient nécessaires. Une fois packrat installé, vous allez pouvoir lancer un projet R associé à cet outil de gestion des packages. Pour cela, soit vous utilisez RStudio et vous aurez juste à cocher &lt;code&gt;Use packrat with this project&lt;/code&gt; au moment de définir le nom de votre projet, soit vous lancez &lt;code&gt;packrat::init(&amp;quot;~/projects/nom de votre projet&amp;quot;)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;À ce stade, vous êtes dans un projet R classique, sauf que vous devriez voir un dossier packrat au niveau de votre projet. Ce dossier contient le fameux fichier &lt;em&gt;packrat.lock&lt;/em&gt; dont nous parlions en début d’article, un fichier &lt;em&gt;packrat.opts&lt;/em&gt; qui enregistre les options que vous avez définies pour packrat, un fichier &lt;em&gt;init.R&lt;/em&gt; qui permet de lancer automatiquement packrat à l’ouverture de votre projet, le dossier &lt;em&gt;src&lt;/em&gt; avec les versions compressées des packages et des dossiers &lt;em&gt;lib&lt;/em&gt; dans lesquels seront installés les packages. En plus, si vous utilisez RStudio, vous allez voir apparaître une section &lt;em&gt;packrat library&lt;/em&gt; à l’endroit où RStudio recense les packages installés.&lt;/p&gt;
&lt;p&gt;À partir du moment où vous êtes dans un projet packrat, toutes vos instructions &lt;code&gt;install.packages()&lt;/code&gt; vont installer vos packages dans la librairie définie par packrat, et toutes vos instructions &lt;code&gt;library()&lt;/code&gt; vont chercher à charger les packages se trouvant dans celle-ci. Pour autant, les installations que vous réalisez ne seront enregistrées dans le fichier &lt;em&gt;lock&lt;/em&gt; que lorsque vous le spécifierez (à moins de définir les options packrat pour qu’il le fasse automatiquement, mais je ne vous le recommande pas). Si vous ne savez plus où vous en êtes de vos installations par rapport à ce qui était préalablement défini dans le fichier &lt;em&gt;lock&lt;/em&gt; vous devez lancer l’instruction &lt;code&gt;packrat::status()&lt;/code&gt;. Elle listera les packages que vous avez installés mais qui ne sont pas enregistrés dans le fichier &lt;em&gt;lock&lt;/em&gt;, mais aussi les packages que vous n’avez pas et qui sont enregistrés dans le fichier &lt;em&gt;lock&lt;/em&gt;. Vous pouvez alors décider d’enregistrer vos changements dans le fichier &lt;em&gt;lock&lt;/em&gt; avec &lt;code&gt;packrat::snapshot()&lt;/code&gt; ou au contraire de revenir à la version du fichier &lt;em&gt;lock&lt;/em&gt; avec &lt;code&gt;packrat::restore()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Packrat est également capable de vérifier que les librairies qu’il charge sont bien utilisées dans le projet R. Si ça n’est pas le cas, il le signale lors d’un &lt;code&gt;packrat::status()&lt;/code&gt;. On peut alors les supprimer avec &lt;code&gt;packrat::clean()&lt;/code&gt;. Cet outil peut s’avérer très utile, car il est difficile de vérifier si les packages installés sont bien utilisés. Mais il faut avoir en tête que tout chargement de package avec &lt;code&gt;library()&lt;/code&gt; suffira à packrat pour considérer que le package est utilisé, même si aucune des fonctions des packages n’est utilisée ensuite. C’est pourquoi il peut être intéressant, notamment pour des fonctions peu utilisées dans un projet, d’utiliser la syntaxe &lt;code&gt;nomlib::nomfonction&lt;/code&gt; plutôt que de charger automatiquement la librairie. Ainsi, si la fonction est supprimée, la référence à la librairie le sera également et packrat pourra vous proposer de désinstaller cette librairie non utilisée.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;utiliser-packrat-avec-un-outil-de-gestion-de-versions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Utiliser packrat avec un outil de gestion de versions&lt;/h1&gt;
&lt;p&gt;En gestion de versions, packrat permet de s’assurer que n’importe qui téléchargeant le projet que vous partagez pourra le faire tourner avec la même distribution de packages que celle utilisée par la dernière personne ayant fait une modification sur celui-ci. Pour cela, il ne suffit de versionner que les fichiers &lt;em&gt;init.R&lt;/em&gt; et &lt;em&gt;packrat.lock&lt;/em&gt;. En effet, les dossiers &lt;em&gt;lib&lt;/em&gt; et &lt;em&gt;src&lt;/em&gt; vont dépendre du système d’exploitation utilisé et seront de toute façon créées automatiquement par packrat et le fichier &lt;em&gt;packrat.opts&lt;/em&gt; doit pouvoir rester spécifique à chaque utilisateur, notamment pour pouvoir définir le dossier dans lequel R devra chercher dans les cas rares où l’utilisateur voudrait charger un package local (avec &lt;code&gt;packrat::extlib&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;Une fois le dépôt défini ainsi, chaque utilisateur qui ouvrira le projet R se verra proposer automatiquement l’installation de packrat si le package n’est pas installé sur son poste puis pourra télécharger automatiquement les packages associés au projet avec &lt;code&gt;packrat::restore()&lt;/code&gt;. Vous pouvez en faire l’expérience en clônant par exemple un projet test dont le dépôt se trouve sur &lt;a href=&#34;https://github.com/AntoineSir/Test_packrat/tree/master/mon_projet&#34;&gt;ma page github&lt;/a&gt;. En ouvrant le fichier &lt;em&gt;.Rproj&lt;/em&gt;, R va chercher à installer automatiquement packrat. Une fois l’installation effectuée, vous pouvez lancer &lt;code&gt;packrat::status()&lt;/code&gt; pour voir les packages associés au projet puis &lt;code&gt;packrat::restore()&lt;/code&gt; pour qu’ils soient installés sur votre poste.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;quelques-limites&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Quelques limites&lt;/h1&gt;
&lt;p&gt;Un des inconvénients les plus notables de packrat est que l’installation des packages prend manifestement plus de temps que lors d’une instruction &lt;code&gt;install.packages&lt;/code&gt;. Cela vient sans doute des processus de lecture du fichier &lt;em&gt;lock&lt;/em&gt;, de création des dossiers de librairies, etc… Cela n’est cependant pas rédhibitoire dans la mesure où l’installation des packages n’est pas censé se faire souvent, à moins de changer de poste constamment.&lt;/p&gt;
&lt;p&gt;Un autre point à signaler est que sous windows, l’installation de &lt;code&gt;data.table 1.12.0&lt;/code&gt; ne fonctionnait pas avec packrat. Cela n’était pas dû à packrat mais à un défaut de &lt;code&gt;data.table&lt;/code&gt;, corrigé depuis (la version sur le CRAN est la 1.12.2). Pour ceux que ça intéresse le bug est expliqué &lt;a href=&#34;https://github.com/Rdatatable/data.table/issues/3329&#34;&gt;ici&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Enfin, l’utilisation de packrat pourrait être un frein si pour une raison ou pour une autre il était impossible de l’installer sur un poste ou s’il ne fonctionnait pas correctement (comme dans le cas du bug avec &lt;code&gt;data.table&lt;/code&gt; par exemple). Il semble alors impossible de charger des packages. Ce problème peut cependant se contourner en téléchargeant les packages en local sur une autre session R et en utilisant &lt;code&gt;packrat::extlib()&lt;/code&gt; pour les charger dans le projet défini avec packrat. Il suffit pour cela d’indiquer dans les options de packrat le dossier dans lequel packrat doit aller chercher les packages chargés en local (d’où l’intérêt de ne pas mettre dans le dépôt le fichier d’options, puisque cette option est dépendante du poste utilisé). Packrat ne tracera pas les packages chargés ainsi.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;pour-finir&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Pour finir…&lt;/h1&gt;
&lt;p&gt;Packrat est donc un outil très pratique de gestion des packages, et il est gratuit. Si ces avantages sont évidents pour des projets collaboratifs, il est aussi intéressant à utiliser pour des projets personnels qu’on pourrait vouloir refaire tourner quelques années plus tard sans que l’évolution des packages ne soit un frein à cela. En l’utilisant avec un système de gestion de versions, le fait de pouvoir revenir à une installation identique à celle qui existait à un moment où le code tournait est un avantage à ne pas sous-estimer, surtout dans un langage où les packages évoluent constamment. Attention cependant : cela ne fonctionne que tant que le la version du package est encore référencée dans les archives du CRAN.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Astuces d&#39;optimisation d&#39;un script R</title>
      <link>/post/astuces-d-optimisation-d-un-script-r/</link>
      <pubDate>Fri, 18 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/astuces-d-optimisation-d-un-script-r/</guid>
      <description>&lt;p&gt;On regroupe ici quelques astuces pour optimiser le temps d’exécution d’un code R. On en propose pour l’instant quatre, mais le post pourra être actualisé par la suite. L’idée est de regrouper des situations auxquelles chacun pourrait être confronté. Les points explorés dans cette note sont les suivants :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pour base R : la question de &lt;a href=&#34;#definition-dune-fonction-apply-sur-les-colonnes-dun-dataframe&#34;&gt;l’application d’une fonction apply aux colonnes d’un data.frame&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Pour dplyr : la &lt;a href=&#34;#ralentissement-de-la-vitesse-dexecution-pour-une-creation-de-variable-directement-a-linterieur-de-summarise&#34;&gt;création d’une variable directement à l’intérieur de summarise()&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Pour dplyr : le temps d’exécution d’un &lt;a href=&#34;#group_by-par-une-variable-caractere&#34;&gt;group_by par une variable caractère&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Pour dplyr : les &lt;a href=&#34;#ralentissement-de-la-vitesse-dexecution-pour-une-statistique-sur-une-variable-booleenne&#34;&gt;summarise() sur des booléens&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;definition-dune-fonction-apply-sur-les-colonnes-dun-dataframe&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Définition d’une fonction apply sur les colonnes d’un dataframe&lt;/h1&gt;
&lt;p&gt;Imaginons que vous souhaitiez appliquer une fonction à un ensemble de variables d’un data.frame, définies dans une liste (par exemple pour faire une fonction qui appliquerait des statistiques sur un ensemble de variables choisies par l’utilisateur). On définit donc une telle liste de variables, dans la table &lt;code&gt;flights&lt;/code&gt; du package &lt;code&gt;nycflights13&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;var &amp;lt;- c(&amp;quot;dep_delay&amp;quot;, &amp;quot;arr_delay&amp;quot;, &amp;quot;air_time&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;On sort ensuite les moyennes de ces trois variables avec &lt;code&gt;sapply&lt;/code&gt;. En base R, cela peut s’écrire ainsi :&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Option 1&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sapply(var, function(x) sum(flights[[x]], na.rm = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## dep_delay arr_delay  air_time 
##   4152200   2257174  49326610&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Mais aussi ainsi :&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Option 2&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sapply(flights[var], function(x) sum(x, na.rm = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## dep_delay arr_delay  air_time 
##   4152200   2257174  49326610&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Cette dernière option pouvant se simplifier, puisqu’on n’a pas vraiment besoin de définir notre fonction à la volée dans ce cas :&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Option 2 bis&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sapply(flights[var], sum, na.rm = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## dep_delay arr_delay  air_time 
##   4152200   2257174  49326610&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ainsi, l’option 2 peut sembler à juste titre plus intuitive (ne serait-ce que parce qu’elle se simplifie avec l’option 2bis), pourtant l’option 1 est significativement plus rapide, comme le montre la fonction &lt;code&gt;microbenchmark&lt;/code&gt; :&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Unit: milliseconds
##          expr      min       lq     mean   median       uq      max neval
##      Option 1 1.568429 1.578101 1.664026 1.580945 1.595168 2.863791    50
##      Option 2 1.917159 1.926831 1.991547 1.935932 1.980875 2.935472    50
##  Option 2 bis 1.910902 1.920004 1.956117 1.934794 1.962102 2.326759    50&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;C’est bon à savoir, mais pour ce genre de traitement ça vaut le coup de s’intéresser aux méthodes &lt;code&gt;dplyr&lt;/code&gt; et &lt;code&gt;data.table&lt;/code&gt; qui offrent des solutions faciles et efficaces.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;group_by-par-une-variable-caractere&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;group_by par une variable caractère&lt;/h1&gt;
&lt;p&gt;Quelque chose de très simple à faire pour optimiser ses codes en dplyr : ne pas faire de group_by sur des variables caractères mais sur des factors. On montre ici un exemple très simple sur la même base flights. Tout d’abord, faisons une moyenne des retards à l’arrivée groupée par le lieu d’origine :&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flightstib %&amp;gt;% group_by(origin) %&amp;gt;% 
  summarize(mean_delay = mean(arr_delay, na.rm = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;On compare la rapidité de cette instruction, à celle-ci, qui fait la même chose sur une variable factor :&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flightstib$originfac &amp;lt;- as.factor(flightstib$origin)
flightstib %&amp;gt;% group_by(originfac) %&amp;gt;% 
  summarize(mean_delay = mean(arr_delay, na.rm = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Le résultat de la fonction &lt;code&gt;microbenchmark&lt;/code&gt; appliquée à ces deux instructions donne :&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Unit: milliseconds
##                expr      min       lq     mean   median       uq      max
##  group by character 14.53741 14.74278 15.99699 14.82441 15.64134 25.96469
##     group by factor 11.86932 12.05932 13.04685 12.13243 12.29911 18.96564
##  neval
##    100
##    100&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;La différence est de l’ordre de 20% et peut peser encore plus sur des tables plus volumineuses. Elle est attendue car le type factor est plus léger et convient parfaitement pour des statistiques groupées. Mais cela semble jouer particulièrement pour les instructions sur dplyr, comme le suggère &lt;a href=&#34;https://github.com/tidyverse/dplyr/issues/2198&#34;&gt;cette discussion sur le github de dplyr&lt;/a&gt;. À noter qu’on ne compte pas dans la comparaison le temps de transposition d’une variable caractère en factor, puisque celui-ci peut être appliqué une seule fois pour de nombreuses instructions ou être appliqué au moment de l’import des bases.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ralentissement-de-la-vitesse-dexecution-pour-une-creation-de-variable-directement-a-linterieur-de-summarise&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Ralentissement de la vitesse d’exécution pour une création de variable directement à l’intérieur de summarise()&lt;/h1&gt;
&lt;p&gt;Si on reprend l’exemple donné dans &lt;a href=&#34;https://antoinesir.rbind.io/post/vitesses-d-agr%C3%A9gation-de-data-table-et-dplyr/&#34;&gt;le précédent post&lt;/a&gt;, vous avez pu remarquer que :&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Rappel : df &amp;lt;- data.frame(id1 = c(1:100), idgpe = sample(50), replace = TRUE)
df %&amp;gt;% as_tibble() %&amp;gt;% mutate(var = rnorm(100)) %&amp;gt;% 
group_by(idgpe) %&amp;gt;% summarise(var_mean = mean(var)) -&amp;gt; output_tibble&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;pouvait se réécrire de manière plus directe (comme le fait d’ailleurs la partie sur data.table) ainsi :&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df %&amp;gt;% as_tibble() %&amp;gt;%  group_by(idgpe) %&amp;gt;% 
  summarise(var_mean = mean(rnorm(100))) -&amp;gt; output_tibble&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;C’est-à-dire en se passant du &lt;code&gt;mutate&lt;/code&gt; pour remplacer &lt;code&gt;var&lt;/code&gt; par sa valeur dans &lt;code&gt;summarise&lt;/code&gt;.&lt;br /&gt;
Hé bien, cette instruction n’est pas seulement présentée ainsi pour le plaisir de vous montrer la fonction &lt;code&gt;mutate&lt;/code&gt;, mais aussi parce que la première option est bien plus rapide que la seconde, comme le montre la fonction &lt;code&gt;microbenchmark&lt;/code&gt; :&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;microbenchmark::microbenchmark(times=100L, dplyr1 = {
  df %&amp;gt;% as_tibble() %&amp;gt;% mutate(var = rnorm(100)) %&amp;gt;% 
    group_by(idgpe) %&amp;gt;% summarise(var_mean = mean(var)) 
}, dplyr2 = {
  df %&amp;gt;% as_tibble() %&amp;gt;% group_by(idgpe) %&amp;gt;% 
    summarise(var_mean = mean(rnorm(100))) 
})&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Unit: milliseconds
##    expr      min       lq     mean   median       uq       max neval
##  dplyr1 1.510403 1.553923 1.598069 1.574118 1.609106  1.888715   100
##  dplyr2 2.557160 2.628840 2.894916 2.655293 2.713036 12.905264   100&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ca peut sembler secondaire pour cet exemple, mais sur des grosses tables la différence va vraiment peser. Regardons par exemple les différences de performance de deux instructions &lt;code&gt;dplyr&lt;/code&gt; agrégeant par heure une variable égale au pourcentage de retard à l’arrivée par rapport à la durée du vol en utilisant les données de &lt;code&gt;nycflights13&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;microbenchmark::microbenchmark(times=10L, dplyr_mutate = {
flightstib %&amp;gt;% mutate(propor_delay = arr_delay / air_time) %&amp;gt;% 
group_by(time_hour) %&amp;gt;% 
summarise(propor_delay = mean(propor_delay)) -&amp;gt; output_dplyr 
}, dplyr_sans_mutate = {
flightstib %&amp;gt;% group_by(time_hour) %&amp;gt;% 
summarise(propor_delay = mean(arr_delay / air_time)) -&amp;gt; output_dplyr 
})&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Unit: milliseconds
##               expr      min        lq      mean    median        uq
##       dplyr_mutate  24.1488  24.64203  25.23982  24.67844  25.79005
##  dplyr_sans_mutate 203.7348 205.64452 211.34958 208.19116 213.98445
##        max neval
##   28.70845    10
##  238.19298    10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Les performances changent du tout au tout. Il semblerait donc que cela soit une très mauvais pratique d’essayer de “sauter” l’étape du &lt;code&gt;mutate()&lt;/code&gt;, sans doute parce que le &lt;code&gt;group_by&lt;/code&gt; peine à traiter le regroupement d’une opération de variables pas encore regroupées. C’est une propriété de &lt;code&gt;summarise&lt;/code&gt; qu’il est important d’avoir à l’esprit.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ralentissement-de-la-vitesse-dexecution-pour-une-statistique-sur-une-variable-booleenne&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Ralentissement de la vitesse d’exécution pour une statistique sur une variable booléenne&lt;/h1&gt;
&lt;p&gt;Imaginons maintenant que l’on crée une variable booléenne indiquant si le pourcentage de retard à l’arrivée est supérieur à 20%.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flightstib %&amp;gt;% mutate(bool_delay = (arr_delay / air_time &amp;gt; 0.20)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;On peut vouloir savoir combien de vols connaisent un retard supérieur à 20% à chaque heure, en agrégeant cette première variable et en appliquant un sum() sur celle-ci.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flightstib %&amp;gt;% mutate(bool_delay = (arr_delay / air_time &amp;gt; 0.20)) %&amp;gt;% 
  group_by(time_hour) %&amp;gt;% summarise(delay_over_20p = sum(bool_delay)) -&amp;gt; stats&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Cette instruction tourne sans problèmes, mais lentement du fait de la difficulté de &lt;code&gt;dplyr&lt;/code&gt; à traiter une somme sur un booléen. Il vaut mieux alors définir dans &lt;code&gt;mutate&lt;/code&gt; la variable &lt;code&gt;bool_delay&lt;/code&gt; comme une variable numérique avec &lt;code&gt;as.numeric(arr_delay / air_time &amp;gt; 0.20)&lt;/code&gt; pour optimiser la rapidité du code. Le tableau suivant donne le résultat du microbenchmark de ces deux options :&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Unit: milliseconds
##              expr       min       lq      mean    median        uq
##              bool 150.76373 154.0661 171.61047 157.65526 160.14871
##  as.numeric(bool)  25.38386  25.6666  27.45456  26.93977  28.94454
##        max neval
##  301.75275    10
##   31.40669    10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Les gains en temps d’exécution sont particulièrement importants. On ne constate pas une telle différence avec &lt;code&gt;data.table&lt;/code&gt; par exemple.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Vitesses d&#39;aggrégation de base R, data.table et dplyr</title>
      <link>/post/vitesses-d-agr%C3%A9gation-de-data-table-et-dplyr/</link>
      <pubDate>Tue, 11 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/vitesses-d-agr%C3%A9gation-de-data-table-et-dplyr/</guid>
      <description>&lt;p&gt;Comme on a pu le voir par exemple dans le &lt;a href=&#34;https://antoinesir.rbind.io/post/comparaisons-base-r-dplyr-data-table/&#34;&gt;précédent post&lt;/a&gt;, l’aggrégation est souvent utilisée en analyse de données. Il est donc intéressant de comparer les performances des différentes options que propose R de ce point de vue. Des benchmarks comparant &lt;code&gt;data.table&lt;/code&gt;, &lt;code&gt;dplyr&lt;/code&gt; et la librairie &lt;code&gt;pandas&lt;/code&gt; de python sur différentes tailles de tables ont déjà été faits, vous pouvez les trouver sur &lt;a href=&#34;https://github.com/Rdatatable/data.table/wiki/Benchmarks-%3A-Grouping&#34;&gt;cette page github&lt;/a&gt;. On propose ici quelques tests comparatifs complémentaires sur un cas d’un calcul simple à partir d’un groupement d’une base fictive de &lt;code&gt;nbrow&lt;/code&gt; lignes appartenant à &lt;code&gt;nbgpe&lt;/code&gt; groupes. La fonction s’applique à deux variables numériques &lt;code&gt;x&lt;/code&gt; et &lt;code&gt;y&lt;/code&gt;, la première étant une variable aléatoire et la seconde un entier dont on fait varier le nombre de modalités. On teste l’instruction suivante :&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pour dplyr&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;datatib %&amp;gt;% group_by(y) %&amp;gt;% summarise(x = mean(x))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Pour data.table&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dataDT[, .(x = mean(x)), by = .(y = y)]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Pour base R&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tap &amp;lt;- tapply(test$x, test$y, mean)
data.frame(x = tap, y = names(tap))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notons que dans ce dernier cas, on ajoute une étape pour transformer l’output en dataframe. On aurait aussi pu utiliser la fonction &lt;code&gt;aggregate&lt;/code&gt; qui permet cela.&lt;/p&gt;
&lt;p&gt;Il n’y a plus qu’à tester! On propose des tests sur 10 000, 100 000 et 1 million de lignes avec à chaque fois peu (1/1000e du nombre de lignes) ou beaucoup (la moitié du nombre de lignes) de groupes. On fait un tableau récapitulatif des différents graphiques issus de la fonction &lt;code&gt;autoplot&lt;/code&gt; de &lt;code&gt;ggplot2&lt;/code&gt; qui sort joliment les résultats de &lt;code&gt;microbenchmark&lt;/code&gt; (on regroupe ces graphiques à l’aide du package &lt;code&gt;gridExtra&lt;/code&gt;). Les graphiques représentent la distribution du temps d’exécution des 10 occurences testées par méthode.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-11-15-vitesses-d-agrégation-de-data-table-et-dplyr_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Le premier constat est que la méthode &lt;code&gt;data.table&lt;/code&gt; est toujours plus rapide que les alternatives testées. Le second est que R base concurrence &lt;code&gt;dplyr&lt;/code&gt; dans tous les cas où le nombre de groupes sur lesquels il faut agréger est petit. Au contraire, la fonction &lt;code&gt;tapply&lt;/code&gt; est largement en dessous des performances des deux autres options quand le nombre de groupes est élevé.&lt;br /&gt;
Le changement d’échelle du graphique à chaque hypothèse testée est trompeur mais ne doit pas cacher que dans le cas d’une table à 1 million de lignes et 50 000 groupes, si l’option &lt;code&gt;dplyr&lt;/code&gt; fait largement mieux que R base, elle est aussi plus surpassée que jamais par data.table. Regardons le graphique de résultats de cette hypothèse pour mieux s’en rendre compte :&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-11-15-vitesses-d-agrégation-de-data-table-et-dplyr_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Les temps d’exécution de &lt;code&gt;data.table&lt;/code&gt; se situent autour de 100 millisecondes alors que ceux de &lt;code&gt;dplyr&lt;/code&gt; sont autour de 800 millisecondes.&lt;/p&gt;
&lt;p&gt;Ces tests confirment ceux cités en introduction de ce post. Ils montrent l’intérêt d’utiliser &lt;code&gt;data.table&lt;/code&gt; dans le cas d’instructions agrégées si l’on souhaite optimiser le temps d’exécution de son script et/ou si l’on connaît des difficultés à gérer des tables volumineuses. Ils montrent aussi que &lt;code&gt;dplyr&lt;/code&gt; reste une option crédible et très compétitive notamment par rapport aux fonctions de base R.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Comparaisons base R - dplyr - data.table</title>
      <link>/post/comparaisons-base-r-dplyr-data-table/</link>
      <pubDate>Mon, 03 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/comparaisons-base-r-dplyr-data-table/</guid>
      <description>&lt;p&gt;La richesse de R, alimentée par une communauté de développeurs très active, rend le choix d’une méthode adaptée à une problématique donnée difficile, et c’est tant mieux. Vous trouverez ici une modeste participation au débat qui oppose les deux packages d’analyse des données les plus en vue dans la communauté R : &lt;code&gt;data.table&lt;/code&gt; et &lt;code&gt;dplyr&lt;/code&gt;. L’article se présente en deux parties :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#rappels-sur-dplyr-et-data.table&#34;&gt;Un rappel sur les syntaxes de dplyr et data.table&lt;/a&gt;, que vous pouvez passer si vous connaissez déjà les packages.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#comparaisons-sur-une-etude-de-cas-simple&#34;&gt;Une comparaison de l’efficacité des deux packages&lt;/a&gt; sur une étude de cas à partir des données du package &lt;code&gt;nycflights13&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;rappels-sur-dplyr-et-data.table&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Rappels sur dplyr et data.table&lt;/h1&gt;
&lt;p&gt;Si vous connaissez déjà la syntaxe de ces packages, vous pouvez directement aller à la partie &lt;a href=&#34;#comparaisons-sur-une-etude-de-cas-simple&#34;&gt;Comparaisons sur une étude de cas simple&lt;/a&gt;. On rappelle ici les principales caractéristiques de ces packages mais pour se former à leur utilisation on peut se référer au &lt;a href=&#34;https://teaching.slmc.fr/perf/presentation_handout.pdf&#34;&gt;cours de perfectionnement de Martin Chevalier&lt;/a&gt;. Pour une exploration de ce qu’englobe le &lt;code&gt;tidyverse&lt;/code&gt; et notamment une présentation des commandes de &lt;code&gt;dplyr&lt;/code&gt;, vous pouvez jeter un oeil à &lt;a href=&#34;https://juba.github.io/tidyverse/index.html&#34;&gt;l’introduction à R et au tidyverse&lt;/a&gt; de J. Barnier. Enfin pour data.table, on trouve des informations utiles sur le cours &lt;a href=&#34;http://larmarange.github.io/analyse-R/manipulations-avancees-avec-data-table.html&#34;&gt;Manipulations avancée avec data.table&lt;/a&gt; de J. Larmarange.&lt;/p&gt;
&lt;div id=&#34;dplyr-et-le-tidyverse&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;dplyr et le tidyverse&lt;/h2&gt;
&lt;p&gt;Le &lt;code&gt;tidyverse&lt;/code&gt; (contraction de “tidy” et “universe”) est un concept initié par Hadley Wickham, chef statisticien de RStudio. Il regroupe un ensemble de packages utiles au traitement statistique et au nettoyage de bases de données. On va s’intéresser ici presque seulement au package &lt;code&gt;dplyr&lt;/code&gt; (dont les instructions seront appliquées aux &lt;code&gt;tibbles&lt;/code&gt;, un format de data.frame issu du &lt;code&gt;tidyverse&lt;/code&gt;), mais vous pouvez parcourir les packages proposés dans le tidyverse sur &lt;a href=&#34;https://www.tidyverse.org/&#34;&gt;le site officiel&lt;/a&gt;.&lt;br /&gt;
&lt;code&gt;dplyr&lt;/code&gt; propose un ensemble d’opérations de traitement de données sous une syntaxe différente de celle utilisée dans les fonctions de base de R. Ce langage présente le double avantage d’être à la fois lisible pour quelqu’un habitué aux langages tels que SAS ou SQL et de proposer des fonctions optimisées qui présentent de bonnes performances en termes de temps d’exécution. La grammaire &lt;code&gt;dplyr&lt;/code&gt; s’appuie en effet sur des fonctions au nom explicite :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;mutate(data, newvar1=fonction(var1,var2...))&lt;/code&gt; et &lt;code&gt;transmute(data, newvar1=fonction(var1,var2...))&lt;/code&gt; créent de nouvelles variables&lt;/li&gt;
&lt;li&gt;&lt;code&gt;filter(data, condition)&lt;/code&gt; sélectionne au sein d’une table certaines observations, à la manière de &lt;code&gt;where&lt;/code&gt; dans SAS.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;arrange(data, var1, descending var2,...)&lt;/code&gt; trie une base selon une ou plusieurs variables (l’équivalent d’une &lt;code&gt;proc sort&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;select(data, var1 : varX)&lt;/code&gt; sélectionne certaines variables dans une base, à la manière de &lt;code&gt;keep&lt;/code&gt; dans SAS.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;summarise(data, newvar1=mean(var1), newvar2=sum(var2))&lt;/code&gt; réalise toute sorte d’opérations statistiques sur une table.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;group_by(data, var)&lt;/code&gt; regroupe une table par une variable&lt;/li&gt;
&lt;li&gt;et bien d’autres…&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Un aspect pratique de ce langage est que toutes ces opérations peuvent être chaînées à l’aide de l’opérateur &lt;code&gt;%&amp;gt;%&lt;/code&gt; (“pipe” en anglais) dont la syntaxe est la suivante : &lt;code&gt;data %&amp;gt;% fonction(...)&lt;/code&gt; est équivalent à &lt;code&gt;fonction(data, ...)&lt;/code&gt;. Cette syntaxe permet de chaîner un grand nombre d’opérations sur une base commune, en limitant le nombre de fois où l’on écrit des tables intermédiaires tout en conservant une grande lisibilité du code. Ce petit exemple vous en convaincra peut-être :&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse) # On aurait aussi pu charger seulement le package dplyr
# on crée un data frame avec 100 lignes, chaque individu appartenant à un des 50 groupes
df &amp;lt;- data.frame(id1 = c(1:100), idgpe = sample(50), replace = TRUE)

# on y applique les instructions de dplyr
df %&amp;gt;% as_tibble() %&amp;gt;% mutate(var = rnorm(100)) %&amp;gt;% 
  group_by(idgpe) %&amp;gt;% summarise(var_mean = mean(var)) -&amp;gt; output_tibble&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Un regard peu habitué contesterait peut-être l’aspect très lisible de l’instruction, mais ça l’est réellement. Le déroulé est le suivant :&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;on transforme notre data.frame en tibble (pour rappel : format optimisé de data.frame pour dplyr) avec &lt;code&gt;as_tibble&lt;/code&gt;&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;on crée une variable &lt;code&gt;var&lt;/code&gt; avec &lt;code&gt;mutate&lt;/code&gt;&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;on agrège par &lt;code&gt;idgpe&lt;/code&gt; avec &lt;code&gt;group_by&lt;/code&gt;&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;on calcule la moyenne de &lt;code&gt;var&lt;/code&gt; avec &lt;code&gt;summarise&lt;/code&gt;, que l’on stocke dans &lt;code&gt;var_mean&lt;/code&gt;. Comme cette instruction suit un group_by, elle est réalisée à l’intérieur de chaque groupe (défini par &lt;code&gt;idgpe&lt;/code&gt;), sinon elle aurait été réalisé sur l’ensemble de la table.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Tout cela est stocké dans une table output_tibble, qui est ainsi un tibble agrégé par &lt;code&gt;idgpe&lt;/code&gt; et qui a donc 50 lignes. L’intérêt de ce chaînage est qu’il permet une économie de code et d’écriture d’éventuelles tables intermédiaires.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data.table&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data.table&lt;/h2&gt;
&lt;p&gt;Le package &lt;code&gt;data.table&lt;/code&gt; ne prétend pas, contrairement au &lt;code&gt;tidyverse&lt;/code&gt;, proposer une syntaxe concurrente à base R mais enrichir celle-ci. Il est axé autour d’un nouveau format d’objet, le data.table, qui est un type de data.frame qui permet une utilisation optimisée de l’opérateur &lt;code&gt;[&lt;/code&gt;.&lt;br /&gt;
Tout data.frame peut être converti en data.table grâce à la fonction &lt;code&gt;as.data.table&lt;/code&gt;, ou, de manière plus optimale pour l’utilisation de la mémoire, grâce à la fonction &lt;code&gt;setDT&lt;/code&gt; qui permet de directement transformer la nature de l’objet sans avoir à en écrire un autre. Il est important d’avoir en tête qu’un data.frame converti en data.table conserve les caractéristiques d’un data.frame. Cependant, l’opérateur &lt;code&gt;[&lt;/code&gt; appliqué au data.table change de signification et devient :&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;DT[i,j,by]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Avec &lt;code&gt;i&lt;/code&gt; qui permet de sélectionner des observations (sans avoir besoin de répéter le nom de la base dans laquelle on se trouve), &lt;code&gt;j&lt;/code&gt; qui permet de créer ou sélectionner des variables et &lt;code&gt;by&lt;/code&gt; de regrouper les traitement selon les modalités d’une variable définie. Comme dans &lt;code&gt;dplyr&lt;/code&gt;, il est possible de chaîner les opérations réalisées comme le montre l’exemple suivant, qui reprend le même cas de figure que celui illustrant le package &lt;code&gt;dplyr&lt;/code&gt; :&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(data.table) 
# on convertit notre data frame précédemment créé en data.table
dt &amp;lt;- as.data.table(df)

# on y applique les même instructions
dt[, list(var_mean = mean(rnorm(100))), by = list(idgpe = idgpe)] -&amp;gt; output_dt&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Le fait de renseigner mes variables au sein de &lt;code&gt;list()&lt;/code&gt; me permet d’avoir une table en sortie au niveau de &lt;code&gt;idgpe&lt;/code&gt; (donc 50 observations), sans cela ma variable est bien moyennée par groupe mais la table en sortie est toujours au niveau &lt;code&gt;id1&lt;/code&gt; (100 observations).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;vitesses-dexecution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Vitesses d’exécution&lt;/h2&gt;
&lt;p&gt;Voilà donc pour les présentations! Allez, on montre le résultat d’un petit &lt;code&gt;microbenchmark&lt;/code&gt; des deux juste pour voir :&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Unit: microseconds
##        expr      min       lq      mean   median        uq      max neval
##       dplyr 1531.449 1567.289 1753.4469 1596.303 1856.0005 4545.422   100
##  data.table  819.201  856.178  919.2454  901.405  974.7915 1233.921   100&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Sur cet exemple, on voit un avantage clair à data.table! Mais on est sur une toute petite table en entrée. On va essayer de se rapprocher de cas plus concrets en s’intéressant à un exemple sur des bases plus importantes.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;comparaisons-sur-une-etude-de-cas-simple&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Comparaisons sur une étude de cas simple&lt;/h1&gt;
&lt;p&gt;Les avantages et inconvénients de ces deux packages sont à l’origine de nombreux débats. Vous pouvez vous en convaincre en suivant &lt;a href=&#34;https://stackoverflow.com/questions/21435339/data-table-vs-dplyr-can-one-do-something-well-the-other-cant-or-does-poorly&#34;&gt;cette discussion sur stackoverflow&lt;/a&gt;. On peut quand même dégager deux compromis :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Le choix de l’un ou l’autre des packages dépend beaucoup de ce que l’on va en faire (types d’analyses, taille des données, profils des utilisateurs du code…).&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Les deux packages sont plus intéressants que base R pour l’analyse de données, que ce soit en termes de facilité d’écriture ou de performances.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Pour ce deuxième point, on va essayer de s’en convaincre ensemble avec ce petit exemple.&lt;/p&gt;
&lt;div id=&#34;notre-etude-de-cas&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Notre étude de cas&lt;/h2&gt;
&lt;p&gt;Pour cet exemple, on utilise les données du package de Hadley Wickham que l’on trouve dans &lt;code&gt;nycflights13&lt;/code&gt;. En particulier, la base &lt;code&gt;flights&lt;/code&gt; donne toutes les heures de départ et d’arrivée selon les aéroports de départ et d’arrivée ainsi que les retards au départ et à l’arrivée. La base &lt;code&gt;weather&lt;/code&gt; donne elle des indications météo, heure par heure, dans chaque aéroport. Tout bon statisticien qui se respecte devrait commencer à se dire qu’il y a quelque chose à faire pour tenter d’expliquer les retards des avions (&lt;em&gt;spoiler alert&lt;/em&gt; : on ne va pas le faire).&lt;br /&gt;
Commençons par charger nos packages (n’oubliez pas de faire &lt;code&gt;install.packages(&amp;quot;nom_pck&amp;quot;)&lt;/code&gt; avant si vous ne l’avez jamais fait) et nos données :&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Les packages nécessaires
library(tidyverse) # Regroupe différents packages, voir https://www.tidyverse.org/ 
library(data.table)
library(microbenchmark) # Pour les calculs de vitesse d&amp;#39;exécution
library(nycflights13) # Pour les données

# data.table pour tests avec data.table
flightsdt &amp;lt;- as.data.table(flights)
weatherdt &amp;lt;- as.data.table(weather)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notez que l’on n’est pas obligés de faire du dplyr sur des tibbles plutôt que des data frame, mais on suit ici les recommandations d’Hadley Wickham.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;moyenne-des-retards-et-fusion-des-tables&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Moyenne des retards et fusion des tables&lt;/h2&gt;
&lt;p&gt;Un rapide examen des bases vous montre que la première étape avant toute analyse est comme souvent de regrouper les éléments de flights par heure et aéroport de départ pour pouvoir les fusionner avec la table weather, qui donnent les indications météo minute par minute. On écrit cette instruction de 3 manières différentes :&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;En base R&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flights_time_hour &amp;lt;- aggregate.data.frame(list(arr_delay = flights$arr_delay, 
                                    dep_delay = flights$dep_delay), 
                                      list(time_hour = flights$time_hour, origin = flights$origin), 
                                      mean)
output_base &amp;lt;- merge(weather, flights_time_hour, by = c(&amp;quot;time_hour&amp;quot;, &amp;quot;origin&amp;quot;), sort = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(J’ai utilisé &lt;code&gt;aggregate.data.frame&lt;/code&gt; et pas &lt;code&gt;tapply&lt;/code&gt; pour avoir directement un data.frame en sortie)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;En dplyr&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flights %&amp;gt;% group_by(time_hour, origin) %&amp;gt;% 
  summarise(arr_delay = mean(arr_delay),
            dep_delay = mean(dep_delay)) %&amp;gt;% 
  inner_join(weather, by = c(&amp;quot;time_hour&amp;quot;, &amp;quot;origin&amp;quot;)) -&amp;gt; output_dplyr &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;En data.table&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;output_DT &amp;lt;- merge(flightsdt[, list(arr_perc_delay = mean(arr_delay),
                       dep_perc_delay = mean(dep_delay)), by = c(&amp;quot;time_hour&amp;quot;, &amp;quot;origin&amp;quot;)],
      weatherdt, by = c(&amp;quot;time_hour&amp;quot;, &amp;quot;origin&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;J’ai utilisé la fonction &lt;code&gt;merge&lt;/code&gt; plutôt que &lt;code&gt;DT1[DT2, on = c(&amp;quot;time_hour&amp;quot;, &amp;quot;origin&amp;quot;), nomatch = 0]&lt;/code&gt; car j’ai constaté qu’elle était plus rapide, conformément à ce que montre bien cet &lt;a href=&#34;https://jozefhajnala.gitlab.io/r/r006-merge/&#34;&gt;article du Jozef’s Rblog&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;comparaisons-des-vitesses-dexecution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Comparaisons des vitesses d’exécution&lt;/h2&gt;
&lt;p&gt;Je vous laisse juger de la lisibilité de chacune de ces instructions, qui font toutes la même chose, car c’est finalement assez subjectif. On donne ici les résultats d’un &lt;code&gt;microbenchmark&lt;/code&gt; de ces instructions :&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Unit: milliseconds
##   expr        min         lq       mean     median         uq        max
##   Base 2313.60446 2492.01024 2631.20076 2704.05612 2753.71612 2868.66635
##  DplyR   55.56166   58.76165   62.45664   61.29150   65.58718   71.77726
##     DT   32.77311   33.92625   35.76353   35.02335   38.23842   39.83814
##  neval
##     10
##     10
##     10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Les résultats sont très nettement en faveur des packages &lt;code&gt;dplyr&lt;/code&gt; et &lt;code&gt;data.table&lt;/code&gt;, ce dernier ayant l’avantage. Sans doute existe-t-il des moyens de plus optimiser l’instruction en base R, mais là n’est pas vraiment la question. On voit qu’avec une syntaxe simple et lisible, &lt;code&gt;dplyr&lt;/code&gt; et &lt;code&gt;data.table&lt;/code&gt; font beaucoup mieux que l’instruction qui viendrait à l’esprit d’un statisticien qui n’utiliserait que les premières fonctions venues de base R.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Privacy Policy</title>
      <link>/privacy/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0200</pubDate>
      
      <guid>/privacy/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
