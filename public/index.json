[{"authors":null,"categories":["R"],"content":"On regroupe ici quelques aspects de R qui peuvent parfois sembler surprenants. Ils ont souvent des conséquences sur les vitesses d’exécution des instructions. On en propose pour l’instant trois, mais le post pourra être actualisé par la suite. Les points explorés dans cette note sont les suivants :\n\rPour base R : la question de l’application d’une fonction apply aux colonnes d’un data.frame\rPour dplyr : la création d’une variable directement à l’intérieur de summarise()\rEncore sur dplyr : le temps d’exécution d’un group_by par une variable caractère\r\rDéfinition d’une fonction apply sur les colonnes d’un dataframe\rImaginons que vous souhaitiez appliquer une fonction à un ensemble de variables d’un data.frame, définies dans une liste (par exemple pour faire une fonction qui appliquerait des statistiques sur un ensemble de variables choisies par l’utilisateur). On définit donc une telle liste de variables, dans la table flights du package nycflights13:\nvar \u0026lt;- c(\u0026quot;dep_delay\u0026quot;, \u0026quot;arr_delay\u0026quot;, \u0026quot;air_time\u0026quot;)\rOn sort ensuite les moyennes de ces trois variables avec sapply. Cela peut s’écrire ainsi :\nOption 1\nsapply(var, function(x) sum(flights[[x]], na.rm = TRUE))\r## dep_delay arr_delay air_time ## 4152200 2257174 49326610\rMais aussi ainsi :\nOption 2\nsapply(flights[var], function(x) sum(x, na.rm = TRUE))\r## dep_delay arr_delay air_time ## 4152200 2257174 49326610\rCette dernière option pouvant se simplifier, puisqu’on n’a pas vraiment besoin de définir notre fonction à la volée dans ce cas :\nOption 2 bis\nsapply(flights[var], sum, na.rm = TRUE)\r## dep_delay arr_delay air_time ## 4152200 2257174 49326610\rAinsi, l’option 2 peut sembler à juste titre plus intuitive (ne serait-ce que parce qu’elle se simplifie avec l’option 2bis), pourtant l’option 1 est significativement plus rapide, comme le montre la fonction microbenchmark :\n## Unit: milliseconds\r## expr min lq mean median uq max neval\r## Option 1 1.566721 1.573547 1.611765 1.578667 1.583787 2.639645 50\r## Option 2 1.917155 1.925689 1.958685 1.934791 1.953565 2.739201 50\r## Option 2 bis 1.916018 1.924551 1.955522 1.937352 1.966650 2.112854 50\rJ’ai pu le constater sur d’autres cas, mais je n’ai pas encore d’explications.\n\rgroup_by par une variable caractère\rQuelque chose de très simple à faire pour optimiser ses codes en dplyr : ne pas faire de group_by sur des variables caractères mais sur des factors. On montre ici un exemple très simple sur la même base flights. Tout d’abord, faisons une moyenne des retards à l’arrivée groupée par le lieu d’origine :\nflightstib %\u0026gt;% group_by(origin) %\u0026gt;% summarize(mean_delay = mean(arr_delay, na.rm = TRUE))\rOn compare la rapidité de cette instruction, à celle-ci, qui fait la même chose sur une variable factor :\nflightstib$originfac \u0026lt;- as.factor(flightstib$origin)\rflightstib %\u0026gt;% group_by(originfac) %\u0026gt;% summarize(mean_delay = mean(arr_delay, na.rm = TRUE))\rLe résultat de la fonction microbenchmark appliquée à ces deux instructions donne :\n## Unit: milliseconds\r## expr min lq mean median uq max\r## group by character 14.52259 14.64889 15.83802 14.72028 15.51473 22.46997\r## group by factor 11.82037 12.00611 13.06466 12.05020 12.27065 19.68014\r## neval\r## 100\r## 100\rLa différence est de l’ordre de 20% et peut peser encore plus sur des tables plus volumineuses. Elle est attendue car le type factor est plus léger et convient parfaitement pour des statistiques groupées. Mais cela semble jouer particulièrement pour les instructions sur dplyr, comme le suggère cette discussion sur le github de dplyr. À noter qu’on ne compte pas dans la comparaison le temps de transposition d’une variable caractère en factor, puisque celui-ci peut être appliqué une seule fois pour de nombreuses instructions ou être appliqué au moment de l’import des bases.\n\rRalentissement de la vitesse d’exécution pour une création de variable directement à l’intérieur de summarise()\rSi on reprend l’exemple donné dans le précédent post, vous avez pu remarquer que :\n# Rappel : df \u0026lt;- data.frame(id1 = c(1:100), idgpe = sample(50), replace = TRUE)\rdf %\u0026gt;% as_tibble() %\u0026gt;% mutate(var = rnorm(100)) %\u0026gt;% group_by(idgpe) %\u0026gt;% summarise(var_mean = mean(var)) -\u0026gt; output_tibble\rpouvait se réécrire de manière plus directe (comme le fait d’ailleurs la partie sur data.table) ainsi :\ndf %\u0026gt;% as_tibble() %\u0026gt;% group_by(idgpe) %\u0026gt;% summarise(var_mean = mean(rnorm(100))) -\u0026gt; output_tibble\rC’est-à-dire en se passant du mutate pour remplacer var par sa valeur dans summarise.\nHé bien, cette instruction n’est pas seulement présentée ainsi pour le plaisir de vous montrer la fonction mutate, mais aussi parce que la première option est bien plus rapide que la seconde, comme le montre la fonction microbenchmark :\nmicrobenchmark::microbenchmark(times=100L, dplyr1 = {\rdf %\u0026gt;% as_tibble() %\u0026gt;% mutate(var = rnorm(100)) %\u0026gt;% group_by(idgpe) %\u0026gt;% summarise(var_mean = mean(var)) }, dplyr2 = {\rdf %\u0026gt;% as_tibble() %\u0026gt;% group_by(idgpe) %\u0026gt;% summarise(var_mean = mean(rnorm(100))) })\r## Unit: milliseconds\r## expr min lq mean median uq max neval\r## dplyr1 1.512677 1.543964 1.604017 1.561600 1.581511 3.729066 100\r## dplyr2 2.577067 2.634809 2.836776 2.653582 2.684019 12.101402 100\rCa peut sembler secondaire pour cet exemple, mais sur des grosses tables la différence va vraiment peser. Regardons par exemple les différences de performance de deux instructions dplyr agrégeant par heure une variable égale au pourcentage de retard à l’arrivée par rapport à la durée du vol en utilisant les données de nycflights13:\nmicrobenchmark::microbenchmark(times=10L, dplyr_mutate = {\rflightstib %\u0026gt;% mutate(propor_delay = arr_delay / air_time) %\u0026gt;% group_by(time_hour) %\u0026gt;% summarise(propor_delay = mean(propor_delay)) -\u0026gt; output_dplyr }, dplyr_sans_mutate = {\rflightstib %\u0026gt;% group_by(time_hour) %\u0026gt;% summarise(propor_delay = mean(arr_delay / air_time)) -\u0026gt; output_dplyr })\r## Unit: milliseconds\r## expr min lq mean median uq\r## dplyr_mutate 24.34275 24.43207 24.80583 24.54158 25.14545\r## dplyr_sans_mutate 203.42608 205.53153 211.44138 208.27813 211.88545\r## max neval\r## 25.83722 10\r## 239.99823 10\rLes performances changent du tout au tout. Il semblerait donc que cela soit une très mauvais pratique d’essayer de “sauter” l’étape du mutate(), sans doute parce que le group_by peine à traiter le regroupement d’une opération de variables pas encore regroupées. C’est une propriété de summarise qu’il est important d’avoir à l’esprit.\n\r","date":1542931200,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1542931200,"objectID":"11d9174fab24be9e3bb856af28f8f3c0","permalink":"/post/quelques-particularit%C3%A9s-de-dplyr/","publishdate":"2018-11-23T00:00:00Z","relpermalink":"/post/quelques-particularit%C3%A9s-de-dplyr/","section":"post","summary":"On regroupe ici quelques aspects de R qui peuvent parfois sembler surprenants. Ils ont souvent des conséquences sur les vitesses d’exécution des instructions. On en propose pour l’instant trois, mais le post pourra être actualisé par la suite. Les points explorés dans cette note sont les suivants :\n\rPour base R : la question de l’application d’une fonction apply aux colonnes d’un data.frame\rPour dplyr : la création d’une variable directement à l’intérieur de summarise()\rEncore sur dplyr : le temps d’exécution d’un group_by par une variable caractère\r\rDéfinition d’une fonction apply sur les colonnes d’un dataframe\rImaginons que vous souhaitiez appliquer une fonction à un ensemble de variables d’un data.","tags":["benchmark","dplyr","microbenchmark","tidyverse","R"],"title":"Quelques astuces du langage R","type":"post"},{"authors":null,"categories":["R"],"content":"Comme on a pu le voir par exemple dans le précédent post, l’aggrégation est souvent utilisée en analyse de données. Il est donc intéressant de comparer les performances de data.table et dplyr de ce point de vue. Des benchamrks ont déjà été faits, et on peut les trouver cette discussion sur stackoverflow évoquée plus haut. On propose ici quelques tests comparatifs complémentaires sur un cas de groupement d’une base fictive de nbrow lignes appartenant à nbgpe groupes. La fonction est la suivante :\nlibrary(tidyverse)\rlibrary(data.table)\rlibrary(microbenchmark)\rtest_group_by \u0026lt;- function(nbrow, nbgpe){\rtest \u0026lt;- as_tibble(data.frame(x = rnorm(nbrow), y = sample(floor(nbgpe), replace = TRUE)))\rtestDT \u0026lt;- as.data.table(test)\rreturn(autoplot(\rmicrobenchmark::microbenchmark(times = 10, unit=\u0026quot;ms\u0026quot;, DplyR = test %\u0026gt;% group_by(y) %\u0026gt;% summarise(x = mean(x)),\rdata.table = testDT[, x:= mean(x), by = y]),\rlog = FALSE)\r+ ggtitle(paste0(nbrow, \u0026quot; lignes pour \u0026quot;, nbgpe, \u0026quot; groupes \u0026quot;)))\r}\rNotez qu’on en profite pour se faire mousser facilement avec autoplot de ggplot2 qui sort les résultats de microbenchmark sous forme d’un joli graphique.\nIl n’y a plus qu’à tester! On propose des tests sur 10 000, 100 000 et 1 million de lignes avec à chaque fois peu (1/1000e du nombre de lignes) ou beaucoup (la moitié du nombre de lignes) de groupes. On fait un tableau récapitulatif des différents graphiques (avec l’aide du package gridExtra) : ","date":1542240000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1542240000,"objectID":"9cd901bcec499a0e6e0f5d220a1b87e2","permalink":"/post/vitesses-d-agr%C3%A9gation-de-data-table-et-dplyr/","publishdate":"2018-11-15T00:00:00Z","relpermalink":"/post/vitesses-d-agr%C3%A9gation-de-data-table-et-dplyr/","section":"post","summary":"Comme on a pu le voir par exemple dans le précédent post, l’aggrégation est souvent utilisée en analyse de données. Il est donc intéressant de comparer les performances de data.table et dplyr de ce point de vue. Des benchamrks ont déjà été faits, et on peut les trouver cette discussion sur stackoverflow évoquée plus haut. On propose ici quelques tests comparatifs complémentaires sur un cas de groupement d’une base fictive de nbrow lignes appartenant à nbgpe groupes.","tags":["benchmark","data.table","dplyr","tidyverse","microbenchmark"],"title":"Vitesses d'agrégation de data.table et dplyr","type":"post"},{"authors":null,"categories":["R"],"content":"La richesse de R, alimentée par une communauté de développeurs très active, rend le choix d’une méthode adaptée à une problématique donnée difficile, et c’est tant mieux. Vous trouverez ici une modeste participation au débat qui oppose les deux packages d’analyse des données les plus en vue dans la communauté R : data.table et dplyr. L’article se présente en deux parties :\n\rUn rappel sur les syntaxes de dplyr et data.table, que vous pouvez passer si vous connaissez déjà les packages.\rUne comparaison de l’efficacité des deux packages sur une étude de cas à partir des données du package nycflights13\r\rRappels sur dplyr et data.table\rSi vous connaissez déjà la syntaxe de ces packages, vous pouvez directement aller à la partie Comparaisons sur une étude de cas simple. On rappelle ici les principales caractéristiques de ces packages mais pour se former à leur utilisation on peut se référer à l’excellent cours de perfectionnement de Martin Chevalier. Pour une exploration de ce qu’englobe le tidyverse et notamment une présentation des commandes de dplyr, vous pouvez jeter un oeil à l’introduction à R et au tidyverse de J. Barnier. Enfin pour data.table, on trouve des informations utiles sur le cours Manipulations avancée avec data.table de J. Larmarange.\ndplyr et le tidyverse\rLe tidyverse (contraction de “tidy” et “universe”) est un concept initié par Hadley Wickham, chef statisticien de RStudio. Il regroupe un ensemble de packages utiles au traitement statistique et au nettoyage de bases de données. On va s’intéresser ici presque seulement au package dplyr (dont les instructions seront appliquées aux tibbles, un format de data.frame issu du tidyverse), mais vous pouvez parcourir les packages proposés dans le tidyverse sur le site officiel.\ndplyr propose un ensemble d’opérations de traitement de données sous une syntaxe différente de celle utilisée dans les fonctions de base de R. Ce langage présente le double avantage d’être à la fois lisible pour quelqu’un habitué aux langages tels que SAS ou SQL et de proposer des fonctions optimisées qui présentent de bonnes performances en termes de temps d’exécution. La grammaire dplyr s’appuie en effet sur des fonctions au nom explicite :\n\rmutate(data, newvar1=fonction(var1,var2...)) et transmute(data, newvar1=fonction(var1,var2...)) créent de nouvelles variables\rfilter(data, condition) sélectionne au sein d’une table certaines observations, à la manière de where dans SAS.\rarrange(data, var1, descending var2,...) trie une base selon une ou plusieurs variables (l’équivalent d’une proc sort).\rselect(data, var1 : varX) sélectionne certaines variables dans une base, à la manière de keep dans SAS.\rsummarise(data, newvar1=mean(var1), newvar2=sum(var2)) réalise toute sorte d’opérations statistiques sur une table.\rgroup_by(data, var) regroupe une table par une variable\ret bien d’autres…\r\rUn aspect pratique de ce langage est que toutes ces opérations peuvent être chaînées à l’aide de l’opérateur %\u0026gt;% (“pipe”) dont la syntaxe est la suivante : data %\u0026gt;% fonction(...) est équivalent à fonction(data, ...). Cette syntaxe permet de chaîner un grand nombre d’opérations sur une base commune, en limitant le nombre de fois où l’on écrit des tables intermédiaires tout en conservant une grande lisibilité du code. Ce petit exemple vous en convaincra peut-être :\nlibrary(tidyverse) # On aurait aussi pu charger seulement le package dplyr\r# on crée un data frame avec 100 lignes, chaque individu appartenant à un des 50 groupes\rdf \u0026lt;- data.frame(id1 = c(1:100), idgpe = sample(50), replace = TRUE)\r# on y applique les instructions de dplyr\rdf %\u0026gt;% as_tibble() %\u0026gt;% mutate(var = rnorm(100)) %\u0026gt;% group_by(idgpe) %\u0026gt;% summarise(var_mean = mean(var)) -\u0026gt; output_tibble\rUn regard peu habitué contesterait peut-être l’aspect très lisible de l’instruction, mais ça l’est réellement. Le déroulé est le suivant :\non transforme notre data.frame en tibble (pour rappel : format optimisé de data.frame pour dplyr) avec as_tibble\n\ron crée une variable var avec mutate\n\ron agrège par idgpe avec group_by\n\ron calcule la moyenne de var avec summarise, que l’on stocke dans var_mean. Comme cette instruction suit un group_by, elle est réalisée à l’intérieur de chaque groupe (défini par idgpe), sinon elle aurait été réalisé sur l’ensemble de la table.\r\rTout cela est stocké dans une table output_tibble, qui est (si vous avez suivi) un tibble agrégé par idgpe et qui a donc 50 lignes.\n\rData.table\rLe package data.table ne prétend pas, contrairement au tidyverse, proposer une syntaxe concurrente à base R mais enrichir celle-ci. Il est axé autour d’un nouveau format d’objet, le data.table, qui est un type de data.frame qui permet une utilisation optimisée de l’opérateur [.\nTout data.frame peut être converti en data.table grâce à la fonction as.data.table, ou, de manière plus optimale pour l’utilisation de la mémoire, grâce à la fonction setDT qui permet de directement transformer la nature de l’objet sans avoir à en écrire un autre. Il est important d’avoir en tête qu’un data.frame converti en data.table conserve les caractéristiques d’un data.frame. Cependant, l’opérateur [ appliqué au data.table change de signification et devient :\nDT[i,j,by]\rAvec i qui permet de sélectionner des observations (sans avoir besoin de répéter le nom de la base dans laquelle on se trouve), j qui permet de créer ou sélectionner des variables et by de regrouper les traitement selon les modalités d’une variable définie. Comme dans dplyr, il est possible de chaîner les opérations réalisées comme le montre l’exemple suivant, qui reprend le même cas de figure que celui illustrant le package dplyr :\nlibrary(data.table) # on convertit notre data frame précédemment créé en data.table\rdt \u0026lt;- as.data.table(df)\r# on y applique les même instructions\rdt[, list(var_mean = mean(rnorm(100))), by = list(idgpe = idgpe)] -\u0026gt; output_dt\rLe fait de renseigner mes variables au sein de list() me permet d’avoir une table en sortie au niveau de idgpe (donc 50 observations), sans cela ma variable est bien moyennée par groupe mais la table en sortie est toujours au niveau id1 (100 observations).\n\rVitesses d’exécution\rVoilà donc pour les présentations! Allez, on montre le résultat d’un petit microbenchmark des deux juste pour voir :\n## Unit: microseconds\r## expr min lq mean median uq max neval\r## dplyr 1539.983 1584.6405 1779.172 1631.005 1868.801 4469.760 100\r## data.table 833.992 850.2055 937.905 891.450 1005.512 1517.227 100\rSur cet exemple, on voit un avantage clair à data.table! Mais on est sur une toute petite table en entrée. On va essayer de se rapprocher de cas plus concrets en s’intéressant à un exemple sur des bases plus importantes.\n\r\rComparaisons sur une étude de cas simple\rLes avantages et inconvénients de ces deux packages sont à l’origine de nombreux débats. Vous pouvez vous en convaincre en suivant cette discussion sur stackoverflow. On peut quand même dégager deux compromis :\n\rLe choix de l’un ou l’autre des packages dépend beaucoup de ce que l’on va en faire (types d’analyses, taille des données, profils des utilisateurs du code…).\n\rLes deux packages sont plus intéressants que base R pour l’analyse de données, que ce soit en termes de facilité d’écriture ou de performances.\r\rPour ce deuxième point, on va essayer de s’en convaincre ensemble avec ce petit exemple.\nNotre étude de cas\rPour cet exemple, on utilise les données du package de Hadley Wickham (oui, le même qui est à l’origine du tidyverse, mais ça n’entamera pas notre indépendance) que l’on trouve dans nycflights13. En particulier, la base flights donne toutes les heures de départ et d’arrivée selon les aéroports de départ et d’arrivée ainsi que les retards au départ et à l’arrivée. La base weather donne elle des indications météo, heure par heure, dans chaque aéroport. Tout bon statisticien qui se respecte devrait commencer à se dire qu’il y a quelque chose à faire pour tenter d’expliquer les retards des avions (spoiler alert : on ne va pas le faire).\nCommençons par charger nos packages (n’oubliez pas de faire install.packages(\u0026quot;nom_pck\u0026quot;) avant si vous ne l’avez jamais fait) et nos données :\n# Les packages nécessaires\rlibrary(tidyverse) # Regroupe différents packages, voir https://www.tidyverse.org/ library(data.table)\rlibrary(microbenchmark) # Pour les calculs de vitesse d\u0026#39;exécution\rlibrary(nycflights13) # Pour les données\r# data frame classiques pour tests en base R\rflights \u0026lt;- as.data.frame(flights)\rweather \u0026lt;- as.data.frame(weather)\r# data.table pour tests avec data.table\rflightsdt \u0026lt;- as.data.table(flights)\rweatherdt \u0026lt;- as.data.table(weather)\r# tibbles pour instructions en dplyR (tournent aussi sur data.frame et data.table)\rflightstib \u0026lt;- as_tibble(flights)\rweathertib \u0026lt;- as_tibble(weather)\rNotez que l’on n’est pas obligés de faire du dplyr sur des tibbles plutôt que des data frame, mais on suit ici les recommandations d’Hadley Wickham.\n\rMoyenne des retards et fusion des tables\rUn rapide examen des bases vous montre que la première étape avant toute analyse est comme souvent de regrouper les éléments de flights par heure et aéroport de départ (ou aurait aussi pu prendre aéroport d’arrivée) pour pouvoir les fusionner avec la table weather, qui donnent les indications météo minute par minute. On écrit cette instruction de manières différentes :\nEn base R\nflights_time_hour \u0026lt;- aggregate.data.frame(list(arr_delay = flights$arr_delay, dep_delay = flights$dep_delay), list(time_hour = flights$time_hour, origin = flights$origin), mean)\routput_base \u0026lt;- merge(weather, flights_time_hour, by = c(\u0026quot;time_hour\u0026quot;, \u0026quot;origin\u0026quot;), sort = FALSE)\r(J’ai utilisé aggregate.data.frame et pas tapply pour avoir directement un data.frame en sortie)\nEn dplyr\nflightstib %\u0026gt;% group_by(time_hour, origin) %\u0026gt;% summarise(arr_delay = mean(arr_delay),\rdep_delay = mean(dep_delay)) %\u0026gt;% inner_join(weathertib, by = c(\u0026quot;time_hour\u0026quot;, \u0026quot;origin\u0026quot;)) -\u0026gt; output_dplyr \rEn data.table\noutput_DT \u0026lt;- merge(flightsdt[, list(arr_perc_delay = mean(arr_delay),\rdep_perc_delay = mean(dep_delay)), by = c(\u0026quot;time_hour\u0026quot;, \u0026quot;origin\u0026quot;)],\rweatherdt, by = c(\u0026quot;time_hour\u0026quot;, \u0026quot;origin\u0026quot;))\rJ’ai utilisé la fonction merge plutôt que DT1[DT2, on = c(\u0026quot;time_hour\u0026quot;, \u0026quot;origin\u0026quot;), nomatch = 0] car j’ai constaté qu’elle était plus rapide, conformément à ce que montre bien cet article du Jozef’s Rblog.\n\rComparaisons des vitesses d’exécution\rJe vous laisse juger de la lisibilité de chacune de ces instructions, qui font toutes la même chose, car c’est finalement assez subjectif. On donne ici les résultats d’un microbenchmark de ces instructions :\n## Unit: milliseconds\r## expr min lq mean median uq max\r## Base 2532.70001 2547.65211 2614.52265 2588.78021 2644.28924 2764.51591\r## DplyR 60.37445 60.89670 62.54289 62.48617 63.71156 64.82658\r## DT 34.58730 35.04184 36.93675 35.48301 35.80700 50.99746\r## neval\r## 10\r## 10\r## 10\rLes résultats sont très nettement en faveur des packages dplyr et data.table, ce dernier ayant l’avantage. Sans doute existe-t-il des moyens de plus optimiser l’instruction en base R, mais là n’est pas vraiment la question. On voit qu’avec une syntaxe simple et lisible, dplyr et data.table font beaucoup mieux que l’instruction qui viendrait à l’esprit d’un statisticien qui n’utiliserait que les premières fonctions venues de base R.\n\r\r","date":1540944000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1540944000,"objectID":"937384c0dfe46505fb927a8a484b0356","permalink":"/post/comparaisons-dplyr-data-table-base-r/","publishdate":"2018-10-31T00:00:00Z","relpermalink":"/post/comparaisons-dplyr-data-table-base-r/","section":"post","summary":"La richesse de R, alimentée par une communauté de développeurs très active, rend le choix d’une méthode adaptée à une problématique donnée difficile, et c’est tant mieux. Vous trouverez ici une modeste participation au débat qui oppose les deux packages d’analyse des données les plus en vue dans la communauté R : data.table et dplyr. L’article se présente en deux parties :\n\rUn rappel sur les syntaxes de dplyr et data.","tags":["benchmark","data science","data.table","dplyr","microbenchmark","tidyverse"],"title":"Comparaisons dplyr - data.table - base R","type":"post"},{"authors":null,"categories":null,"content":" In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;\n","date":1536444000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1536444000,"objectID":"6a451186c775f5f0adb3a0416d0cb711","permalink":"/tutorial/example/","publishdate":"2018-09-09T00:00:00+02:00","relpermalink":"/tutorial/example/","section":"tutorial","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;","tags":null,"title":"Example Page","type":"docs"},{"authors":[],"categories":null,"content":"Click on the Slides button above to view the built-in slides feature.\n\rSlides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using url_slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1483225200,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1483225200,"objectID":"cd6d9d084287506b4668ad90c6aff50a","permalink":"/talk/example-talk/","publishdate":"2017-01-01T00:00:00+01:00","relpermalink":"/talk/example-talk/","section":"talk","summary":"Click on the Slides button above to view the built-in slides feature.\n\rSlides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using url_slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.","tags":[],"title":"Example Talk","type":"talk"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461708000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1461708000,"objectID":"80be3c9fcc86014efab0cec0f14957f6","permalink":"/project/deep-learning/","publishdate":"2016-04-27T00:00:00+02:00","relpermalink":"/project/deep-learning/","section":"project","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit.","tags":["Deep Learning"],"title":"Deep Learning","type":"project"},{"authors":null,"categories":null,"content":"","date":1461708000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1461708000,"objectID":"553a94c5dfd3b8b099d8a12b2d248093","permalink":"/project/example-external-project/","publishdate":"2016-04-27T00:00:00+02:00","relpermalink":"/project/example-external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":["GA Cushen"],"categories":null,"content":"More detail can easily be written here using Markdown and $\\rm \\LaTeX$ math code.\n","date":1441058400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1441058400,"objectID":"5cec0ce6e082b377c504bc66cdf990c5","permalink":"/publication/person-re-identification/","publishdate":"2015-09-01T00:00:00+02:00","relpermalink":"/publication/person-re-identification/","section":"publication","summary":"Person re-identification is a critical security task for recognizing a person across spatially disjoint sensors. Previous work can be computationally intensive and is mainly based on low-level cues extracted from RGB data and implemented on a PC for a fixed sensor network (such as traditional CCTV). We present a practical and efficient framework for mobile devices (such as smart phones and robots) where high-level semantic soft biometrics are extracted from RGB and depth data. By combining these cues, our approach attempts to provide robustness to noise, illumination, and minor variations in clothing. This mobile approach may be particularly useful for the identification of persons in areas ill-served by fixed sensors or for tasks where the sensor position and direction need to dynamically adapt to a target. Results on the BIWI dataset are preliminary but encouraging. Further evaluation and demonstration of the system will be available on our website.","tags":[],"title":"A Person Re-Identification System For Mobile Devices","type":"publication"},{"authors":["GA Cushen","MS Nixon"],"categories":null,"content":"More detail can easily be written here using Markdown and $\\rm \\LaTeX$ math code.\n","date":1372629600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1372629600,"objectID":"caae70970030052c8f733b2ca8421a2b","permalink":"/publication/clothing-search/","publishdate":"2013-07-01T00:00:00+02:00","relpermalink":"/publication/clothing-search/","section":"publication","summary":"We present a mobile visual clothing search system whereby a smart phone user can either choose a social networking photo or take a new photo of a person wearing clothing of interest and search for similar clothing in a retail database. From the query image, the person is detected, clothing is segmented, and clothing features are extracted and quantized. The information is sent from the phone client to a server, where the feature vector of the query image is used to retrieve similar clothing products from online databases. The phone's GPS location is used to re-rank results by retail store location. State of the art work focuses primarily on the recognition of a diverse range of clothing offline and pays little attention to practical applications. Evaluated on a challenging dataset, the system is relatively fast and achieves promising results.","tags":[],"title":"Mobile visual clothing search","type":"publication"},{"authors":null,"categories":null,"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne\r Two\r Three\r\nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":-62135596800,"objectID":"c2915ec5da95791851caafdcba9664af","permalink":"/slides/example-slides/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/slides/example-slides/","section":"slides","summary":"Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$","tags":null,"title":"Slides","type":"slides"}]