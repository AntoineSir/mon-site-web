[{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1598514169,"objectID":"0357e8a91d04394c6a7a9c763839bd42","permalink":"/bio/experience_pro/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/bio/experience_pro/","section":"bio","summary":"","tags":null,"title":"Expériences professionnelles","type":"bio"},{"authors":null,"categories":null,"content":"","date":1505858400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1559732108,"objectID":"f646cec68021838ef54af4bc8f933d1e","permalink":"/bio/competences/","publishdate":"2017-09-20T00:00:00+02:00","relpermalink":"/bio/competences/","section":"bio","summary":"","tags":null,"title":"Compétences","type":"bio"},{"authors":null,"categories":null,"content":"","date":1461103200,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1559060858,"objectID":"907ab06af2b4c3b1d07dbe627b64b4fc","permalink":"/bio/publications/","publishdate":"2016-04-20T00:00:00+02:00","relpermalink":"/bio/publications/","section":"bio","summary":"","tags":null,"title":"Principales publications","type":"bio"},{"authors":[],"categories":[],"content":"Vous avez dû voir passer cette information : une mise à jour majeure de dplyr (version 1.0.0) est sortie il y a quelques mois! L’occasion de faire une nouvelle petite note sur un élément très important de cette nouvelle version : across(), un nouveau verbe pour réaliser des opérations sur plusieurs colonnes. On va le présenter rapidement et regarder ensuite ses performances en termes de vitesse d’exécution par rapport aux anciennes méthodes. On utilise la version 1.0.2 de dplyr, celle sur le CRAN à ce jour, et qui a justement été optimisée par rapport à la version 1.0.0. Cette note est organisée en deux parties :\n- across(), ça marche comment?, où l’on présente les bases de across().\n- across(), ça tourne comment?, où l’on évalue la vitesse d’exécution par rapport aux anciennes méthodes.\nSi vous voulez balayer plus largement les différents éléments de la mise à jour de dplyr, vous pouvez vous rendre sur le site du tidyverse (en anglais) ou sur cet article du blog de ThinkR (en français) qui en présentent les changements majeurs.\nacross(), ça marche comment?\rSyntaxe de base\rLe verbe across() vise à remplacer toutes les fonctions suffixées par _if, _at et _all. Il regroupe ces méthodes dans une seule et permet ainsi de les associer, ce qui n’était pas possible avant. Il s’utilise dans mutate et summarise. La syntaxe associée à ce verbe est la suivante :\nacross(.cols, .fns)\rDans laquelle :\n- Les colonnes .cols peuvent être sélectionnées en utilisant la même syntaxe que pour la méthode vars() (nom des variables, starts_with, end_with, contains,…), mais aussi avec des conditions rentrées dans where() qui sélectionneront de la même manière que le faisaient les fonctions suffixées par _if.\n- La fonction .fns est définie comme auparavant (le nom de la fonction ou sa définition “à la volée” avec ~ my_fun(.)).\n\rQuelques exemples\rPour changer, on utilise pour ces petits exemples la table palmerpenguins promue par Allison Horst pour remplacer l’usage de la table iris. Vous pouvez la télécharger avec install.packages(\u0026quot;palmerpenguins\u0026quot;). À partir de cette table, l’instruction visant à sortir la moyenne de toutes les variables numériques s’écrivait auparavant :\npenguins %\u0026gt;% summarise_if(is.numeric, mean, na.rm = TRUE)\r## # A tibble: 1 x 5\r## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g year\r## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 43.9 17.2 201. 4202. 2008.\rElle se réécrit avec across() en utilisant where() :\npenguins %\u0026gt;% summarise(across(where(is.numeric), mean, na.rm = TRUE))\r## # A tibble: 1 x 5\r## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g year\r## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 43.9 17.2 201. 4202. 2008.\rSi l’on souhaite sélectionner à partir du nom des variables, la nouvelle syntaxe est la suivante :\n# Ancienne version\rpenguins %\u0026gt;% summarise_at(vars(matches(\u0026quot;bill*|flipper*\u0026quot;)), mean, na.rm = TRUE)\r## # A tibble: 1 x 3\r## bill_length_mm bill_depth_mm flipper_length_mm\r## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 43.9 17.2 201.\r# Avec across()\rpenguins %\u0026gt;% summarise(across(matches(\u0026quot;bill*|flipper*\u0026quot;), mean, na.rm = TRUE))\r## # A tibble: 1 x 3\r## bill_length_mm bill_depth_mm flipper_length_mm\r## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 43.9 17.2 201.\rOn note également qu’on peut combiner dorénavant les sélections sur les types des colonnes et sur leur nom dans une seule instruction across(), ce qui n’était pas possible avant. Pour enlever les années des moyennes numériques, on peut par exemple écrire :\npenguins %\u0026gt;% summarise(across(where(is.numeric) \u0026amp; -contains(\u0026quot;year\u0026quot;), mean, na.rm = TRUE))\r## # A tibble: 1 x 4\r## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\r## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 43.9 17.2 201. 4202.\rEnfin, le paramètre .names de across() est également très pratique et permet notamment dans une instruction mutate() de créer de nouvelles colonnes nommées à partir des anciennes auxquelles on peut se référer avec .col. Par exemple, si je veux créer deux nouvelles colonnes passant les informations sur le bec en pouces mais en conservant les anciennes colonnes, je peux écrire :\npenguins %\u0026gt;% mutate(across(starts_with(\u0026quot;bill\u0026quot;), ~ . * 0.04, .names = \u0026quot;pouces_{.col}\u0026quot;)) %\u0026gt;% select(contains(\u0026quot;bill\u0026quot;)) %\u0026gt;% head(5)\r## # A tibble: 5 x 4\r## bill_length_mm bill_depth_mm pouces_bill_length_mm pouces_bill_depth_mm\r## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 39.1 18.7 1.56 0.748\r## 2 39.5 17.4 1.58 0.696\r## 3 40.3 18 1.61 0.72 ## 4 NA NA NA NA ## 5 36.7 19.3 1.47 0.772\r\r\racross(), ça tourne comment?\rÀ la sortie de la mise à jour de dplyr, il avait été signalé que la méthode across() impliquerait peut-être de légères pertes en termes de vitesse d’exécution par rapport aux anciennes méthodes _at, _if et _all. Une partie de ce retard a été apparemment rattrapé dans les dernières mises à jour et donc dans la version 1.0.2 que l’on utilise dans cet article. Sur le modèle de ce que l’on a proposé dans un article précédent, on va comparer les instructions _if et _at d’un summarise groupé avec leurs équivalents dans across() pour différentes tailles d’échantillons et de groupes.\nLe tibble utilisé a le format suivant, ici pour 100 lignes et deux groupes :\nnbrow \u0026lt;- 100\rnbgpe \u0026lt;- 2\ras_tibble(data.frame(x1 = rnorm(nbrow), x2 = rnorm(nbrow), x3 = runif(nbrow), x4 = runif(nbrow),\ry = as.factor(sample(floor(nbgpe), replace = TRUE))\r))\r## # A tibble: 100 x 5\r## x1 x2 x3 x4 y ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt;\r## 1 1.30 -0.131 0.756 0.939 1 ## 2 -0.581 0.503 0.190 0.690 1 ## 3 -0.938 -1.49 0.553 0.0348 1 ## 4 1.16 0.404 0.113 0.173 1 ## 5 -0.440 0.590 0.832 0.379 1 ## 6 0.0230 0.0860 0.264 0.0788 1 ## 7 0.570 -0.552 0.429 0.0663 1 ## 8 0.344 1.61 0.901 0.333 1 ## 9 -1.55 0.231 0.318 0.279 1 ## 10 -0.503 0.678 0.0712 0.229 1 ## # ... with 90 more rows\rLes différentes instructions testées sont les suivantes :\n# summarise_if data %\u0026gt;% group_by(y) %\u0026gt;% summarise_if(is.numeric, mean) # across + where() data %\u0026gt;% group_by(y) %\u0026gt;% summarise(across(where(is.numeric), mean)) # summarise_at data %\u0026gt;% group_by(y) %\u0026gt;% summarise_at(vars(starts_with(\u0026quot;x\u0026quot;)), mean) # across + starts_with() data %\u0026gt;% group_by(y) %\u0026gt;% summarise(across(starts_with(\u0026quot;x\u0026quot;), mean))\rLes résultats du microbenchmark() pour les différentes combinaisons de nombres de groupes et de lignes sont présentés dans un graphique qui représente la distribution du temps d’exécution des 10 occurences testées pour chaque méthode :\nOn constate en effet une moins bonne performance en termes de vitesse d’exécution des instructions utilisant le verbe across(). Les différences sont surtout marquées dans le cas où il y a beaucoup de groupes par rapport au nombre de lignes (colonne de droite) et ce quelque soit le nombre de lignes. Elles sont peu importantes dans le cas où il y a peu de groupes par rapport au nombre de lignes (colonne de gauche).\n\r","date":1598486400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1598486400,"objectID":"ed68e758e42525fcf12eb28a7e9ca9af","permalink":"/post/fonctionnement-de-across-dans-dplyr/","publishdate":"2020-08-27T00:00:00Z","relpermalink":"/post/fonctionnement-de-across-dans-dplyr/","section":"post","summary":"Vous avez dû voir passer cette information : une mise à jour majeure de dplyr (version 1.0.0) est sortie il y a quelques mois! L’occasion de faire une nouvelle petite note sur un élément très important de cette nouvelle version : across(), un nouveau verbe pour réaliser des opérations sur plusieurs colonnes. On va le présenter rapidement et regarder ensuite ses performances en termes de vitesse d’exécution par rapport aux anciennes méthodes.","tags":["dplyr","across","benchmark","rstats","R","tidyverse"],"title":"Fonctionnement de across() dans dplyr","type":"post"},{"authors":["Mathias André","Antoine Sireyjol"],"categories":null,"content":"","date":1574208000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1585819454,"objectID":"b7a683caba745341aac1a332beff1ba6","permalink":"/publication/2019-dt/","publishdate":"2019-11-20T00:00:00Z","relpermalink":"/publication/2019-dt/","section":"publication","summary":"Effets redistributifs et budgétaires des mécanismes de quotients conjugal et familial pour le calcul de l'impôt sur le revenu","tags":null,"title":"Imposition des couples et des familles : effets budgétaires et redistributifs de l’impôt sur le revenu","type":"publication"},{"authors":null,"categories":["R"],"content":"Packrat est un système de gestion de packages et de leurs versions permettant de tracer l’installation et l’utilisation de ceux-ci dans un projet R. Cet article vise à vous montrer comment l’utiliser et en quoi il peut vous être utile. Le plan de l’article est le suivant :\n- Packrat, ça sert à quoi?\n- Démarrer son projet avec packrat\n- Utiliser packrat avec un outil de gestion de versions\n- Quelques limites\nEdit 2020\rPour la gestion de packages, renv vise désormais à remplacer packrat. Pour l’utilisateur, le fonctionnement est très semblable mais renv est plus performant, et corrige notamment certains défauts évoqués dans cet article. Vous pouvez découvrir ce package sur le site de RStudio. Il est notamment possible de migrer un projet packrat vers un projet renv avec l’instruction renv::migrate().\n\rPackrat, ça sert à quoi?\rPackrat trace tous les packages installés pour un projet ainsi que leurs dépendances. Ce gestionnaire de packages est lui-même un package R qui peut s’installer avec l’instruction install.packages(\u0026quot;packrat\u0026quot;). La documentation et l’aide pour l’utilisation de packrat sont disponibles ici.\nDans une utilisation classique de R, les packages que vous installez se trouvent généralement tous dans le même dossier, au niveau du dossier d’installation de R. Avec packrat, les packages que vous installez pour votre projet vont se retrouver dans un dossier packrat au niveau de votre projet. Ce seul élément permet déjà de vous assurer que vous allez pouvoir identifier facilement les packages que vous avez installés pour votre projet et pour lui seul. En plus de cela, packrat va recenser à chaque installation de package que vous réalisez la version du package au moment où vous l’avez installé ainsi que les dépendances de celui-ci. Il va mettre ces informations dans un fichier lock. C’est ce fichier qui permet ensuite de pouvoir récupérer l’ensemble des versions des packages utilisées dans votre projet depuis n’importe quel poste.\nCes caractéristiques permettent ainsi de mettre à l’abri votre projet de mises à jours de packages non désirées, puisque la mise à jour de packages sur d’autres projets n’aura pas d’impacts sur votre projet avec packrat. La documentation packrat définit cela comme un projet isolé. La portabilité et la reproductibilité des projets réalisés avec packrat viennent du fait que le fichier lock assure que les packages puissent être installés de n’importe quel poste (et n’importe quel système d’exploitation) et le soient dans la même version pour tout le monde. Dit autrement, si le projet tourne sur un poste, packrat assure qu’il tournera sur n’importe quel poste. Nous allons essayer de vous montrer concrètement comment cela fonctionne.\n\rDémarrer son projet avec packrat\rLa première chose à faire est d’installer le package packrat sur une session R. Il s’appuie lui-même sur les packages tools et unit. Il se peut que les droits d’administrateur sur le poste soient nécessaires. Une fois packrat installé, vous allez pouvoir lancer un projet R associé à cet outil de gestion des packages. Pour cela, soit vous utilisez RStudio et vous aurez juste à cocher Use packrat with this project au moment de définir le nom de votre projet, soit vous lancez packrat::init(\u0026quot;~/projects/nom de votre projet\u0026quot;).\nÀ ce stade, vous êtes dans un projet R classique, sauf que vous devriez voir un dossier packrat au niveau de votre projet. Ce dossier contient le fameux fichier packrat.lock dont nous parlions en début d’article, un fichier packrat.opts qui enregistre les options que vous avez définies pour packrat, un fichier init.R qui permet de lancer automatiquement packrat à l’ouverture de votre projet, le dossier src avec les versions compressées des packages et des dossiers lib dans lesquels seront installés les packages. En plus, si vous utilisez RStudio, vous allez voir apparaître une section packrat library à l’endroit où RStudio recense les packages installés.\nÀ partir du moment où vous êtes dans un projet packrat, toutes vos instructions install.packages() vont installer vos packages dans la librairie définie par packrat, et toutes vos instructions library() vont chercher à charger les packages se trouvant dans celle-ci. Pour autant, les installations que vous réalisez ne seront enregistrées dans le fichier lock que lorsque vous le spécifierez (à moins de définir les options packrat pour qu’il le fasse automatiquement, mais je ne vous le recommande pas). Si vous ne savez plus où vous en êtes de vos installations par rapport à ce qui était préalablement défini dans le fichier lock vous devez lancer l’instruction packrat::status(). Elle listera les packages que vous avez installés mais qui ne sont pas enregistrés dans le fichier lock, mais aussi les packages que vous n’avez pas et qui sont enregistrés dans le fichier lock. Vous pouvez alors décider d’enregistrer vos changements dans le fichier lock avec packrat::snapshot() ou au contraire de revenir à la version du fichier lock avec packrat::restore().\nPackrat est également capable de vérifier que les librairies qu’il charge sont bien utilisées dans le projet R. Si ça n’est pas le cas, il le signale lors d’un packrat::status(). On peut alors les supprimer avec packrat::clean(). Cet outil peut s’avérer très utile, car il est difficile de vérifier si les packages installés sont bien utilisés. Mais il faut avoir en tête que tout chargement de package avec library() suffira à packrat pour considérer que le package est utilisé, même si aucune des fonctions des packages n’est utilisée ensuite. C’est pourquoi il peut être intéressant, notamment pour des fonctions peu utilisées dans un projet, d’utiliser la syntaxe nomlib::nomfonction plutôt que de charger automatiquement la librairie. Ainsi, si la fonction est supprimée, la référence à la librairie le sera également et packrat pourra vous proposer de désinstaller cette librairie non utilisée.\n\rUtiliser packrat avec un outil de gestion de versions\rEn gestion de versions, packrat permet de s’assurer que n’importe qui téléchargeant le projet que vous partagez pourra le faire tourner avec la même distribution de packages que celle utilisée par la dernière personne ayant fait une modification sur celui-ci. Pour cela, il ne suffit de versionner que les fichiers init.R et packrat.lock. En effet, les dossiers lib et src vont dépendre du système d’exploitation utilisé et seront de toute façon créées automatiquement par packrat et le fichier packrat.opts doit pouvoir rester spécifique à chaque utilisateur, notamment pour pouvoir définir le dossier dans lequel R devra chercher dans les cas rares où l’utilisateur voudrait charger un package local (avec packrat::extlib).\nUne fois le dépôt défini ainsi, chaque utilisateur qui ouvrira le projet R se verra proposer automatiquement l’installation de packrat si le package n’est pas installé sur son poste puis pourra télécharger automatiquement les packages associés au projet avec packrat::restore(). Vous pouvez en faire l’expérience en clônant par exemple un projet test dont le dépôt se trouve sur ma page github. En ouvrant le fichier .Rproj, R va chercher à installer automatiquement packrat. Une fois l’installation effectuée, vous pouvez lancer packrat::status() pour voir les packages associés au projet puis packrat::restore() pour qu’ils soient installés sur votre poste.\n\rQuelques limites\rUn des inconvénients les plus notables de packrat est que l’installation des packages prend manifestement plus de temps que lors d’une instruction install.packages. Cela vient sans doute des processus de lecture du fichier lock, de création des dossiers de librairies, etc… Cela n’est cependant pas rédhibitoire dans la mesure où l’installation des packages n’est pas censé se faire souvent, à moins de changer de poste constamment.\nUn autre point à signaler est que sous windows, l’installation de data.table 1.12.0 ne fonctionnait pas avec packrat. Cela n’était pas dû à packrat mais à un défaut de data.table, corrigé depuis (la version sur le CRAN est la 1.12.2). Pour ceux que ça intéresse le bug est expliqué ici.\nEnfin, l’utilisation de packrat pourrait être un frein si pour une raison ou pour une autre il était impossible de l’installer sur un poste ou s’il ne fonctionnait pas correctement (comme dans le cas du bug avec data.table par exemple). Il semble alors impossible de charger des packages. Ce problème peut cependant se contourner en téléchargeant les packages en local sur une autre session R et en utilisant packrat::extlib() pour les charger dans le projet défini avec packrat. Il suffit pour cela d’indiquer dans les options de packrat le dossier dans lequel packrat doit aller chercher les packages chargés en local (d’où l’intérêt de ne pas mettre dans le dépôt le fichier d’options, puisque cette option est dépendante du poste utilisé). Packrat ne tracera pas les packages chargés ainsi.\n\rPour finir…\rPackrat est donc un outil très pratique de gestion des packages, et il est gratuit. Si ces avantages sont évidents pour des projets collaboratifs, il est aussi intéressant à utiliser pour des projets personnels qu’on pourrait vouloir refaire tourner quelques années plus tard sans que l’évolution des packages ne soit un frein à cela. En l’utilisant avec un système de gestion de versions, le fait de pouvoir revenir à une installation identique à celle qui existait à un moment où le code tournait est un avantage à ne pas sous-estimer, surtout dans un langage où les packages évoluent constamment. Attention cependant : cela ne fonctionne que tant que la version du package est encore référencée dans les archives du CRAN.\n\r","date":1557360000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1557360000,"objectID":"9f02eb87397135fe993fc342d45a9456","permalink":"/post/gestion-des-packages-sur-r-pr%C3%A9sentation-de-packrat/","publishdate":"2019-05-09T00:00:00Z","relpermalink":"/post/gestion-des-packages-sur-r-pr%C3%A9sentation-de-packrat/","section":"post","summary":"Packrat est un système de gestion de packages et de leurs versions permettant de tracer l’installation et l’utilisation de ceux-ci dans un projet R. Cet article vise à vous montrer comment l’utiliser et en quoi il peut vous être utile. Le plan de l’article est le suivant :\n- Packrat, ça sert à quoi?\n- Démarrer son projet avec packrat\n- Utiliser packrat avec un outil de gestion de versions","tags":["packrat","R","packages","gestion","projet","renv"],"title":"Gestion des packages sur R : présentation de packrat","type":"post"},{"authors":null,"categories":["R"],"content":"On regroupe ici quelques astuces pour optimiser le temps d’exécution d’un code R. On en propose pour l’instant quatre, mais le post pourra être actualisé par la suite. L’idée est de regrouper des situations auxquelles chacun pourrait être confronté. Les points explorés dans cette note sont les suivants :\n\rPour base R : la question de l’application d’une fonction apply aux colonnes d’un data.frame.\rPour dplyr : la création d’une variable directement à l’intérieur de summarise().\rPour dplyr : le temps d’exécution d’un group_by par une variable caractère.\rPour dplyr : les summarise() sur des booléens\r\rDéfinition d’une fonction apply sur les colonnes d’un dataframe\rImaginons que vous souhaitiez appliquer une fonction à un ensemble de variables d’un data.frame, définies dans une liste (par exemple pour faire une fonction qui appliquerait des statistiques sur un ensemble de variables choisies par l’utilisateur). On définit donc une telle liste de variables, dans la table flights du package nycflights13:\nvar \u0026lt;- c(\u0026quot;dep_delay\u0026quot;, \u0026quot;arr_delay\u0026quot;, \u0026quot;air_time\u0026quot;)\rOn sort ensuite les moyennes de ces trois variables avec sapply. En base R, cela peut s’écrire ainsi :\nOption 1\nsapply(var, function(x) sum(flights[[x]], na.rm = TRUE))\r## dep_delay arr_delay air_time ## 4152200 2257174 49326610\rMais aussi ainsi :\nOption 2\nsapply(flights[var], function(x) sum(x, na.rm = TRUE))\r## dep_delay arr_delay air_time ## 4152200 2257174 49326610\rCette dernière option pouvant se simplifier, puisqu’on n’a pas vraiment besoin de définir notre fonction à la volée dans ce cas :\nOption 2 bis\nsapply(flights[var], sum, na.rm = TRUE)\r## dep_delay arr_delay air_time ## 4152200 2257174 49326610\rAinsi, l’option 2 peut sembler à juste titre plus intuitive (ne serait-ce que parce qu’elle se simplifie avec l’option 2bis), pourtant l’option 1 est significativement plus rapide, comme le montre la fonction microbenchmark :\n## Unit: milliseconds\r## expr min lq mean median uq max neval\r## Option 1 1.568429 1.578101 1.664026 1.580945 1.595168 2.863791 50\r## Option 2 1.917159 1.926831 1.991547 1.935932 1.980875 2.935472 50\r## Option 2 bis 1.910902 1.920004 1.956117 1.934794 1.962102 2.326759 50\rC’est bon à savoir, mais pour ce genre de traitement ça vaut le coup de s’intéresser aux méthodes dplyr et data.table qui offrent des solutions faciles et efficaces.\n\rgroup_by par une variable caractère\rQuelque chose de très simple à faire pour optimiser ses codes en dplyr : ne pas faire de group_by sur des variables caractères mais sur des factors. On montre ici un exemple très simple sur la même base flights. Tout d’abord, faisons une moyenne des retards à l’arrivée groupée par le lieu d’origine :\nflightstib %\u0026gt;% group_by(origin) %\u0026gt;% summarize(mean_delay = mean(arr_delay, na.rm = TRUE))\rOn compare la rapidité de cette instruction, à celle-ci, qui fait la même chose sur une variable factor :\nflightstib$originfac \u0026lt;- as.factor(flightstib$origin)\rflightstib %\u0026gt;% group_by(originfac) %\u0026gt;% summarize(mean_delay = mean(arr_delay, na.rm = TRUE))\rLe résultat de la fonction microbenchmark appliquée à ces deux instructions donne :\n## Unit: milliseconds\r## expr min lq mean median uq max\r## group by character 14.53741 14.74278 15.99699 14.82441 15.64134 25.96469\r## group by factor 11.86932 12.05932 13.04685 12.13243 12.29911 18.96564\r## neval\r## 100\r## 100\rLa différence est de l’ordre de 20% et peut peser encore plus sur des tables plus volumineuses. Elle est attendue car le type factor est plus léger et convient parfaitement pour des statistiques groupées. Mais cela semble jouer particulièrement pour les instructions sur dplyr, comme le suggère cette discussion sur le github de dplyr. À noter qu’on ne compte pas dans la comparaison le temps de transposition d’une variable caractère en factor, puisque celui-ci peut être appliqué une seule fois pour de nombreuses instructions ou être appliqué au moment de l’import des bases.\n\rRalentissement de la vitesse d’exécution pour une création de variable directement à l’intérieur de summarise()\rSi on reprend l’exemple donné dans le précédent post, vous avez pu remarquer que :\n# Rappel : df \u0026lt;- data.frame(id1 = c(1:100), idgpe = sample(50), replace = TRUE)\rdf %\u0026gt;% as_tibble() %\u0026gt;% mutate(var = rnorm(100)) %\u0026gt;% group_by(idgpe) %\u0026gt;% summarise(var_mean = mean(var)) -\u0026gt; output_tibble\rpouvait se réécrire de manière plus directe (comme le fait d’ailleurs la partie sur data.table) ainsi :\ndf %\u0026gt;% as_tibble() %\u0026gt;% group_by(idgpe) %\u0026gt;% summarise(var_mean = mean(rnorm(100))) -\u0026gt; output_tibble\rC’est-à-dire en se passant du mutate pour remplacer var par sa valeur dans summarise.\nHé bien, cette instruction n’est pas seulement présentée ainsi pour le plaisir de vous montrer la fonction mutate, mais aussi parce que la première option est bien plus rapide que la seconde, comme le montre la fonction microbenchmark :\nmicrobenchmark::microbenchmark(times=100L, dplyr1 = {\rdf %\u0026gt;% as_tibble() %\u0026gt;% mutate(var = rnorm(100)) %\u0026gt;% group_by(idgpe) %\u0026gt;% summarise(var_mean = mean(var)) }, dplyr2 = {\rdf %\u0026gt;% as_tibble() %\u0026gt;% group_by(idgpe) %\u0026gt;% summarise(var_mean = mean(rnorm(100))) })\r## Unit: milliseconds\r## expr min lq mean median uq max neval\r## dplyr1 1.510403 1.553923 1.598069 1.574118 1.609106 1.888715 100\r## dplyr2 2.557160 2.628840 2.894916 2.655293 2.713036 12.905264 100\rCa peut sembler secondaire pour cet exemple, mais sur des grosses tables la différence va vraiment peser. Regardons par exemple les différences de performance de deux instructions dplyr agrégeant par heure une variable égale au pourcentage de retard à l’arrivée par rapport à la durée du vol en utilisant les données de nycflights13:\nmicrobenchmark::microbenchmark(times=10L, dplyr_mutate = {\rflightstib %\u0026gt;% mutate(propor_delay = arr_delay / air_time) %\u0026gt;% group_by(time_hour) %\u0026gt;% summarise(propor_delay = mean(propor_delay)) -\u0026gt; output_dplyr }, dplyr_sans_mutate = {\rflightstib %\u0026gt;% group_by(time_hour) %\u0026gt;% summarise(propor_delay = mean(arr_delay / air_time)) -\u0026gt; output_dplyr })\r## Unit: milliseconds\r## expr min lq mean median uq\r## dplyr_mutate 24.1488 24.64203 25.23982 24.67844 25.79005\r## dplyr_sans_mutate 203.7348 205.64452 211.34958 208.19116 213.98445\r## max neval\r## 28.70845 10\r## 238.19298 10\rLes performances changent du tout au tout. Il semblerait donc que cela soit une très mauvais pratique d’essayer de “sauter” l’étape du mutate(), sans doute parce que le group_by peine à traiter le regroupement d’une opération de variables pas encore regroupées. C’est une propriété de summarise qu’il est important d’avoir à l’esprit.\n\rRalentissement de la vitesse d’exécution pour une statistique sur une variable booléenne\rImaginons maintenant que l’on crée une variable booléenne indiquant si le pourcentage de retard à l’arrivée est supérieur à 20%.\nflightstib %\u0026gt;% mutate(bool_delay = (arr_delay / air_time \u0026gt; 0.20)) \rOn peut vouloir savoir combien de vols connaisent un retard supérieur à 20% à chaque heure, en agrégeant cette première variable et en appliquant un sum() sur celle-ci.\nflightstib %\u0026gt;% mutate(bool_delay = (arr_delay / air_time \u0026gt; 0.20)) %\u0026gt;% group_by(time_hour) %\u0026gt;% summarise(delay_over_20p = sum(bool_delay)) -\u0026gt; stats\rCette instruction tourne sans problèmes, mais lentement du fait de la difficulté de dplyr à traiter une somme sur un booléen. Il vaut mieux alors définir dans mutate la variable bool_delay comme une variable numérique avec as.numeric(arr_delay / air_time \u0026gt; 0.20) pour optimiser la rapidité du code. Le tableau suivant donne le résultat du microbenchmark de ces deux options :\n## Unit: milliseconds\r## expr min lq mean median uq\r## bool 150.76373 154.0661 171.61047 157.65526 160.14871\r## as.numeric(bool) 25.38386 25.6666 27.45456 26.93977 28.94454\r## max neval\r## 301.75275 10\r## 31.40669 10\rLes gains en temps d’exécution sont particulièrement importants. On ne constate pas une telle différence avec data.table par exemple.\n\r","date":1547769600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1547807677,"objectID":"e557cbaa563e550e852d8f06e306ae98","permalink":"/post/astuces-d-optimisation-d-un-script-r/","publishdate":"2019-01-18T00:00:00Z","relpermalink":"/post/astuces-d-optimisation-d-un-script-r/","section":"post","summary":"On regroupe ici quelques astuces pour optimiser le temps d’exécution d’un code R. On en propose pour l’instant quatre, mais le post pourra être actualisé par la suite. L’idée est de regrouper des situations auxquelles chacun pourrait être confronté. Les points explorés dans cette note sont les suivants :\n\rPour base R : la question de l’application d’une fonction apply aux colonnes d’un data.frame.\rPour dplyr : la création d’une variable directement à l’intérieur de summarise().","tags":["benchmark","booléens","dplyr","microbenchmark","optimisation","R","sapply"],"title":"Astuces d'optimisation d'un script R","type":"post"},{"authors":null,"categories":["R"],"content":"Comme on a pu le voir par exemple dans le précédent post, l’aggrégation est souvent utilisée en analyse de données. Il est donc intéressant de comparer les performances des différentes options que propose R de ce point de vue. Des benchmarks comparant data.table, dplyr et la librairie pandas de python sur différentes tailles de tables ont déjà été faits, vous pouvez les trouver sur cette page github. On propose ici quelques tests comparatifs complémentaires sur un cas d’un calcul simple à partir d’un groupement d’une base fictive de nbrow lignes appartenant à nbgpe groupes. La fonction s’applique à deux variables numériques x et y, la première étant une variable aléatoire et la seconde un entier dont on fait varier le nombre de modalités. On teste l’instruction suivante :\nPour dplyr\ndatatib %\u0026gt;% group_by(y) %\u0026gt;% summarise(x = mean(x))\rPour data.table\ndataDT[, .(x = mean(x)), by = .(y = y)]\rPour base R\ntap \u0026lt;- tapply(test$x, test$y, mean)\rdata.frame(x = tap, y = names(tap))\rNotons que dans ce dernier cas, on ajoute une étape pour transformer l’output en dataframe. On aurait aussi pu utiliser la fonction aggregate qui permet cela.\nIl n’y a plus qu’à tester! On propose des tests sur 10 000, 100 000 et 1 million de lignes avec à chaque fois peu (1/1000e du nombre de lignes) ou beaucoup (la moitié du nombre de lignes) de groupes. On fait un tableau récapitulatif des différents graphiques issus de la fonction autoplot de ggplot2 qui sort joliment les résultats de microbenchmark (on regroupe ces graphiques à l’aide du package gridExtra). Les graphiques représentent la distribution du temps d’exécution des 10 occurences testées par méthode.\nLe premier constat est que la méthode data.table est toujours plus rapide que les alternatives testées. Le second est que R base concurrence dplyr dans tous les cas où le nombre de groupes sur lesquels il faut agréger est petit. Au contraire, la fonction tapply est largement en dessous des performances des deux autres options quand le nombre de groupes est élevé.\nLe changement d’échelle du graphique à chaque hypothèse testée est trompeur mais ne doit pas cacher que dans le cas d’une table à 1 million de lignes et 50 000 groupes, si l’option dplyr fait largement mieux que R base, elle est aussi plus surpassée que jamais par data.table. Regardons le graphique de résultats de cette hypothèse pour mieux s’en rendre compte :\nLes temps d’exécution de data.table se situent autour de 100 millisecondes alors que ceux de dplyr sont autour de 800 millisecondes.\nCes tests confirment ceux cités en introduction de ce post. Ils montrent l’intérêt d’utiliser data.table dans le cas d’instructions agrégées si l’on souhaite optimiser le temps d’exécution de son script et/ou si l’on connaît des difficultés à gérer des tables volumineuses. Ils montrent aussi que dplyr reste une option crédible et très compétitive notamment par rapport aux fonctions de base R.\n","date":1544486400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1544486400,"objectID":"9cd901bcec499a0e6e0f5d220a1b87e2","permalink":"/post/vitesses-d-agr%C3%A9gation-de-data-table-et-dplyr/","publishdate":"2018-12-11T00:00:00Z","relpermalink":"/post/vitesses-d-agr%C3%A9gation-de-data-table-et-dplyr/","section":"post","summary":"Comme on a pu le voir par exemple dans le précédent post, l’aggrégation est souvent utilisée en analyse de données. Il est donc intéressant de comparer les performances des différentes options que propose R de ce point de vue. Des benchmarks comparant data.table, dplyr et la librairie pandas de python sur différentes tailles de tables ont déjà été faits, vous pouvez les trouver sur cette page github. On propose ici quelques tests comparatifs complémentaires sur un cas d’un calcul simple à partir d’un groupement d’une base fictive de nbrow lignes appartenant à nbgpe groupes.","tags":["benchmark","data.table","dplyr","tidyverse","microbenchmark"],"title":"Vitesses d'aggrégation de base R, data.table et dplyr","type":"post"},{"authors":null,"categories":["R"],"content":"La richesse de R, alimentée par une communauté de développeurs très active, rend le choix d’une méthode adaptée à une problématique donnée difficile, et c’est tant mieux. Vous trouverez ici une modeste participation au débat qui oppose les deux packages d’analyse des données les plus en vue dans la communauté R : data.table et dplyr. L’article se présente en deux parties :\n\rUn rappel sur les syntaxes de dplyr et data.table, que vous pouvez passer si vous connaissez déjà les packages.\rUne comparaison de l’efficacité des deux packages sur une étude de cas à partir des données du package nycflights13\r\rRappels sur dplyr et data.table\rSi vous connaissez déjà la syntaxe de ces packages, vous pouvez directement aller à la partie Comparaisons sur une étude de cas simple. On rappelle ici les principales caractéristiques de ces packages mais pour se former à leur utilisation on peut se référer au cours de perfectionnement de Martin Chevalier. Pour une exploration de ce qu’englobe le tidyverse et notamment une présentation des commandes de dplyr, vous pouvez jeter un oeil à l’introduction à R et au tidyverse de J. Barnier. Enfin pour data.table, on trouve des informations utiles sur le cours Manipulations avancée avec data.table de J. Larmarange.\ndplyr et le tidyverse\rLe tidyverse (contraction de “tidy” et “universe”) est un concept initié par Hadley Wickham, chef statisticien de RStudio. Il regroupe un ensemble de packages utiles au traitement statistique et au nettoyage de bases de données. On va s’intéresser ici presque seulement au package dplyr (dont les instructions seront appliquées aux tibbles, un format de data.frame issu du tidyverse), mais vous pouvez parcourir les packages proposés dans le tidyverse sur le site officiel.\ndplyr propose un ensemble d’opérations de traitement de données sous une syntaxe différente de celle utilisée dans les fonctions de base de R. Ce langage présente le double avantage d’être à la fois lisible pour quelqu’un habitué aux langages tels que SAS ou SQL et de proposer des fonctions optimisées qui présentent de bonnes performances en termes de temps d’exécution. La grammaire dplyr s’appuie en effet sur des fonctions au nom explicite :\n\rmutate(data, newvar1=fonction(var1,var2...)) et transmute(data, newvar1=fonction(var1,var2...)) créent de nouvelles variables\rfilter(data, condition) sélectionne au sein d’une table certaines observations, à la manière de where dans SAS.\rarrange(data, var1, descending var2,...) trie une base selon une ou plusieurs variables (l’équivalent d’une proc sort).\rselect(data, var1 : varX) sélectionne certaines variables dans une base, à la manière de keep dans SAS.\rsummarise(data, newvar1=mean(var1), newvar2=sum(var2)) réalise toute sorte d’opérations statistiques sur une table.\rgroup_by(data, var) regroupe une table par une variable\ret bien d’autres…\r\rUn aspect pratique de ce langage est que toutes ces opérations peuvent être chaînées à l’aide de l’opérateur %\u0026gt;% (“pipe” en anglais) dont la syntaxe est la suivante : data %\u0026gt;% fonction(...) est équivalent à fonction(data, ...). Cette syntaxe permet de chaîner un grand nombre d’opérations sur une base commune, en limitant le nombre de fois où l’on écrit des tables intermédiaires tout en conservant une grande lisibilité du code. Ce petit exemple vous en convaincra peut-être :\nlibrary(tidyverse) # On aurait aussi pu charger seulement le package dplyr\r# on crée un data frame avec 100 lignes, chaque individu appartenant à un des 50 groupes\rdf \u0026lt;- data.frame(id1 = c(1:100), idgpe = sample(50), replace = TRUE)\r# on y applique les instructions de dplyr\rdf %\u0026gt;% as_tibble() %\u0026gt;% mutate(var = rnorm(100)) %\u0026gt;% group_by(idgpe) %\u0026gt;% summarise(var_mean = mean(var)) -\u0026gt; output_tibble\rUn regard peu habitué contesterait peut-être l’aspect très lisible de l’instruction, mais ça l’est réellement. Le déroulé est le suivant :\non transforme notre data.frame en tibble (pour rappel : format optimisé de data.frame pour dplyr) avec as_tibble\n\ron crée une variable var avec mutate\n\ron agrège par idgpe avec group_by\n\ron calcule la moyenne de var avec summarise, que l’on stocke dans var_mean. Comme cette instruction suit un group_by, elle est réalisée à l’intérieur de chaque groupe (défini par idgpe), sinon elle aurait été réalisé sur l’ensemble de la table.\r\rTout cela est stocké dans une table output_tibble, qui est ainsi un tibble agrégé par idgpe et qui a donc 50 lignes. L’intérêt de ce chaînage est qu’il permet une économie de code et d’écriture d’éventuelles tables intermédiaires.\n\rData.table\rLe package data.table ne prétend pas, contrairement au tidyverse, proposer une syntaxe concurrente à base R mais enrichir celle-ci. Il est axé autour d’un nouveau format d’objet, le data.table, qui est un type de data.frame qui permet une utilisation optimisée de l’opérateur [.\nTout data.frame peut être converti en data.table grâce à la fonction as.data.table, ou, de manière plus optimale pour l’utilisation de la mémoire, grâce à la fonction setDT qui permet de directement transformer la nature de l’objet sans avoir à en écrire un autre. Il est important d’avoir en tête qu’un data.frame converti en data.table conserve les caractéristiques d’un data.frame. Cependant, l’opérateur [ appliqué au data.table change de signification et devient :\nDT[i,j,by]\rAvec i qui permet de sélectionner des observations (sans avoir besoin de répéter le nom de la base dans laquelle on se trouve), j qui permet de créer ou sélectionner des variables et by de regrouper les traitement selon les modalités d’une variable définie. Comme dans dplyr, il est possible de chaîner les opérations réalisées comme le montre l’exemple suivant, qui reprend le même cas de figure que celui illustrant le package dplyr :\nlibrary(data.table) # on convertit notre data frame précédemment créé en data.table\rdt \u0026lt;- as.data.table(df)\r# on y applique les même instructions\rdt[, list(var_mean = mean(rnorm(100))), by = list(idgpe = idgpe)] -\u0026gt; output_dt\rLe fait de renseigner mes variables au sein de list() me permet d’avoir une table en sortie au niveau de idgpe (donc 50 observations), sans cela ma variable est bien moyennée par groupe mais la table en sortie est toujours au niveau id1 (100 observations).\n\rVitesses d’exécution\rVoilà donc pour les présentations! Allez, on montre le résultat d’un petit microbenchmark des deux juste pour voir :\n## Unit: microseconds\r## expr min lq mean median uq max neval\r## dplyr 1531.449 1567.289 1753.4469 1596.303 1856.0005 4545.422 100\r## data.table 819.201 856.178 919.2454 901.405 974.7915 1233.921 100\rSur cet exemple, on voit un avantage clair à data.table! Mais on est sur une toute petite table en entrée. On va essayer de se rapprocher de cas plus concrets en s’intéressant à un exemple sur des bases plus importantes.\n\r\rComparaisons sur une étude de cas simple\rLes avantages et inconvénients de ces deux packages sont à l’origine de nombreux débats. Vous pouvez vous en convaincre en suivant cette discussion sur stackoverflow. On peut quand même dégager deux compromis :\n\rLe choix de l’un ou l’autre des packages dépend beaucoup de ce que l’on va en faire (types d’analyses, taille des données, profils des utilisateurs du code…).\n\rLes deux packages sont plus intéressants que base R pour l’analyse de données, que ce soit en termes de facilité d’écriture ou de performances.\r\rPour ce deuxième point, on va essayer de s’en convaincre ensemble avec ce petit exemple.\nNotre étude de cas\rPour cet exemple, on utilise les données du package de Hadley Wickham que l’on trouve dans nycflights13. En particulier, la base flights donne toutes les heures de départ et d’arrivée selon les aéroports de départ et d’arrivée ainsi que les retards au départ et à l’arrivée. La base weather donne elle des indications météo, heure par heure, dans chaque aéroport. Tout bon statisticien qui se respecte devrait commencer à se dire qu’il y a quelque chose à faire pour tenter d’expliquer les retards des avions (spoiler alert : on ne va pas le faire).\nCommençons par charger nos packages (n’oubliez pas de faire install.packages(\u0026quot;nom_pck\u0026quot;) avant si vous ne l’avez jamais fait) et nos données :\n# Les packages nécessaires\rlibrary(tidyverse) # Regroupe différents packages, voir https://www.tidyverse.org/ library(data.table)\rlibrary(microbenchmark) # Pour les calculs de vitesse d\u0026#39;exécution\rlibrary(nycflights13) # Pour les données\r# data.table pour tests avec data.table\rflightsdt \u0026lt;- as.data.table(flights)\rweatherdt \u0026lt;- as.data.table(weather)\rNotez que l’on n’est pas obligés de faire du dplyr sur des tibbles plutôt que des data frame, mais on suit ici les recommandations d’Hadley Wickham.\n\rMoyenne des retards et fusion des tables\rUn rapide examen des bases vous montre que la première étape avant toute analyse est comme souvent de regrouper les éléments de flights par heure et aéroport de départ pour pouvoir les fusionner avec la table weather, qui donnent les indications météo minute par minute. On écrit cette instruction de 3 manières différentes :\nEn base R\nflights_time_hour \u0026lt;- aggregate.data.frame(list(arr_delay = flights$arr_delay, dep_delay = flights$dep_delay), list(time_hour = flights$time_hour, origin = flights$origin), mean)\routput_base \u0026lt;- merge(weather, flights_time_hour, by = c(\u0026quot;time_hour\u0026quot;, \u0026quot;origin\u0026quot;), sort = FALSE)\r(J’ai utilisé aggregate.data.frame et pas tapply pour avoir directement un data.frame en sortie)\nEn dplyr\nflights %\u0026gt;% group_by(time_hour, origin) %\u0026gt;% summarise(arr_delay = mean(arr_delay),\rdep_delay = mean(dep_delay)) %\u0026gt;% inner_join(weather, by = c(\u0026quot;time_hour\u0026quot;, \u0026quot;origin\u0026quot;)) -\u0026gt; output_dplyr \rEn data.table\noutput_DT \u0026lt;- merge(flightsdt[, list(arr_perc_delay = mean(arr_delay),\rdep_perc_delay = mean(dep_delay)), by = c(\u0026quot;time_hour\u0026quot;, \u0026quot;origin\u0026quot;)],\rweatherdt, by = c(\u0026quot;time_hour\u0026quot;, \u0026quot;origin\u0026quot;))\rJ’ai utilisé la fonction merge plutôt que DT1[DT2, on = c(\u0026quot;time_hour\u0026quot;, \u0026quot;origin\u0026quot;), nomatch = 0] car j’ai constaté qu’elle était plus rapide, conformément à ce que montre bien cet article du Jozef’s Rblog.\n\rComparaisons des vitesses d’exécution\rJe vous laisse juger de la lisibilité de chacune de ces instructions, qui font toutes la même chose, car c’est finalement assez subjectif. On donne ici les résultats d’un microbenchmark de ces instructions :\n## Unit: milliseconds\r## expr min lq mean median uq max\r## Base 2313.60446 2492.01024 2631.20076 2704.05612 2753.71612 2868.66635\r## DplyR 55.56166 58.76165 62.45664 61.29150 65.58718 71.77726\r## DT 32.77311 33.92625 35.76353 35.02335 38.23842 39.83814\r## neval\r## 10\r## 10\r## 10\rLes résultats sont très nettement en faveur des packages dplyr et data.table, ce dernier ayant l’avantage. Sans doute existe-t-il des moyens de plus optimiser l’instruction en base R, mais là n’est pas vraiment la question. On voit qu’avec une syntaxe simple et lisible, dplyr et data.table font beaucoup mieux que l’instruction qui viendrait à l’esprit d’un statisticien qui n’utiliserait que les premières fonctions venues de base R.\n\r\r","date":1543795200,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1543858369,"objectID":"4a2710bcf63721f06fd2ebd9ae7fbbc7","permalink":"/post/comparaisons-base-r-dplyr-data-table/","publishdate":"2018-12-03T00:00:00Z","relpermalink":"/post/comparaisons-base-r-dplyr-data-table/","section":"post","summary":"La richesse de R, alimentée par une communauté de développeurs très active, rend le choix d’une méthode adaptée à une problématique donnée difficile, et c’est tant mieux. Vous trouverez ici une modeste participation au débat qui oppose les deux packages d’analyse des données les plus en vue dans la communauté R : data.table et dplyr. L’article se présente en deux parties :\n\rUn rappel sur les syntaxes de dplyr et data.","tags":["benchmark","data science","data.table","dplyr","microbenchmark","tidyverse","R"],"title":"Comparaisons base R - dplyr - data.table","type":"post"},{"authors":["Mathias André","Anne-Lise Biotteau","Marie-Cécile Cazenave","Maëlle Fontaine","Michaël Sicsic","Antoine Sireyjol"],"categories":null,"content":"","date":1479772800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1559060858,"objectID":"9c4b2e90c6fc189ac53691535fd6001e","permalink":"/publication/2016-fps/","publishdate":"2016-11-22T00:00:00Z","relpermalink":"/publication/2016-fps/","section":"publication","summary":"Bilan de l'impact des mesures socio-fiscales en 2015 sur les inégalités et le revenu disponible des ménages en France.","tags":null,"title":"Les réformes des prestations et prélèvements intervenues en 2015 opèrent une légère redistribution des 30 % les plus aisés vers le reste de la population","type":"publication"},{"authors":["Antoine Sireyjol"],"categories":null,"content":"","date":1476576000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1559060858,"objectID":"5ffda9ca852c9102c30b27525b6b0b60","permalink":"/publication/2016-cmuc-acs/","publishdate":"2016-10-16T00:00:00Z","relpermalink":"/publication/2016-cmuc-acs/","section":"publication","summary":"Impact redistributif de deux dispositifs d’aide à la couverture complémentaire santé convertis en avantages monétaires.","tags":null,"title":"La CMU-C et l’ACS réduisent les inégalités en soutenant le pouvoir d’achat des plus modestes","type":"publication"},{"authors":["Mathias André","Marie-Cécile Cazenave","Maëlle Fontaine","Juliette Fourcot","Antoine Sireyjol"],"categories":null,"content":"","date":1448928000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1559060858,"objectID":"fcacb519758c2911c561f093aa6e2198","permalink":"/publication/2015-dt/","publishdate":"2015-12-01T00:00:00Z","relpermalink":"/publication/2015-dt/","section":"publication","summary":"Note méthodologique sur les hypothèses et méthodes utilisées pour mesurer l'impact d'une réforme sur le revenu des ménages en France.","tags":null,"title":"Effet des nouvelles mesures sociales et fiscales sur le niveau de vie des ménages : méthodologie de chiffrage avec le modèle de microsimulation Ines","type":"publication"},{"authors":["Mathias André","Marie-Cécile Cazenave","Maëlle Fontaine","Juliette Fourcot","Antoine Sireyjol"],"categories":null,"content":"","date":1446595200,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1559060858,"objectID":"e1cb5dd8b5b5e97a46fca90ec87b6598","permalink":"/publication/2015-fps/","publishdate":"2015-11-04T00:00:00Z","relpermalink":"/publication/2015-fps/","section":"publication","summary":"Bilan de l'impact des mesures socio-fiscales en 2014 sur les inégalités et le revenu disponible des ménages en France.","tags":null,"title":"Les réformes des prestations et prélèvements intervenues en 2014 pénalisent les 50 % des ménages les plus aisés et épargnent les 10 % les plus modestes","type":"publication"}]